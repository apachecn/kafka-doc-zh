<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<script id="security-template" type="text/x-handlebars-template">
    <h3><a id="security_overview" href="#security_overview">7.1 安全总览</a></h3>
    在0.9.0.0版中，Kafka社区添加了一些特性，通过单独使用或者一起使用这些特性，提高了Kafka集群的安全性。目前支持下列安全措施：
    <ol>
        <li>使用SSL或SASL验证来自客户端(producers和consumers)、其他brokers和工具的连接。Kafka支持以下SASL机制：
        <ul>
            <li>SASL/GSSAPI (Kerberos) - 从版本0.9.0.0开始</li>
            <li>SASL/PLAIN - 从版本0.10.0.0开始</li>
            <li>SASL/SCRAM-SHA-256 和 SASL/SCRAM-SHA-512 - 从版本0.10.2.0开始</li>
        </ul></li>
        <li>验证从brokers 到 ZooKeeper的连接</li>
        <li>对brokers与clients之间、brokers之间或brokers与工具之间使用SSL传输对数据加密(注意，启用SSL时性能会下降，其大小取决于CPU类型和JVM实现)。</li>
        <li>授权客户端的读写操作</li>
        <li>授权是可插拔的，并且支持与外部授权服务的集成</li>
    </ol>

    值得注意的是，安全是可选的 - 支持非安全集群，也支持需要认证，不需要认证，加密和未加密clients的混合集群。

    以下指南介绍了如何在clients和brokers中配置和使用安全功能。

    <h3><a id="security_ssl" href="#security_ssl">7.2 使用SSL加密和授权</a></h3>
    Apache Kafka允许客户端通过SSL进行连接。默认情况下，SSL被禁用，但可以根据需要启用。

    <ol>
        <li><h4><a id="security_ssl_key" href="#security_ssl_key">为每个Kafka broker生成SSL密钥和证书</a></h4>
            部署一个或多个支持SSL的brokers的第一步是为集群中的每台计算机生成密钥和证书。你可以使用Java的keytool实用程序来完成此任务。最初我们将生成一个临时密钥库的密钥，以便我们稍后可以导出并用CA签名。
            <pre class="brush: bash;">
            keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA</pre>

            你需要在上面的命令中指定两个参数：
            <ol>
                <li>keystore: 存储证书的密钥库文件。密钥库文件包含证书的私钥；因此，它需要安全保存。</li>
                <li>validity: 证书有效期。</li>
            </ol>
            <br>
            注意：默认情况下，属性ssl.endpoint.identification.algorithm未定义，所以不执行主机名验证。为了启用主机名验证，请设置以下属性：

        <pre class="brush: text;">	ssl.endpoint.identification.algorithm=HTTPS </pre>

        启用后，客户端将根据以下两个字段之一验证服务器的完全限定域名(FQDN)：
        <ol>
            <li>Common Name (CN)
            <li>Subject Alternative Name (SAN)
        </ol>
        <br>
        这两个字段都是有效的，但RFC-2818建议使用SAN。 SAN也更加灵活，允许声明多个DNS条目。另一个优点是可以将CN设置为更有意义的值用于授权目的。要添加SAN字段，请将以下参数<code> -ext SAN=DNS:{FQDN} </code>附加到keytool命令中：
        <pre class="brush: bash;">
        keytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey -keyalg RSA -ext SAN=DNS:{FQDN}
        </pre>
        之后可以运行以下命令来验证生成的证书内容：
        <pre class="brush: bash;">
        keytool -list -v -keystore server.keystore.jks
        </pre>
        </li>
        <li><h4><a id="security_ssl_ca" href="#security_ssl_ca">创建你自己的证书管理机构 (CA)</a></h4>
            在完成第一步之后, 集群中的每一台机器都有一个公私密钥对, 和一个用于标识该机器的证书. 但是, 这个证书是未签名的, 也就是说攻击者也可以创造一个这样的证书, 假装是其中任何一台机器.<p>
            因此, 给集群中每个机器的证书签名, 来防止伪造的证书, 是非常重要的. 一个证书管理机构 (CA) 负责证书的签名. CA 的工作流程类似政府发放护照. 政府给每一个护照盖章(签名), 因此护照变得难以伪造. 其他政府通过验证这个盖章来确认护照是可信的. 同理, CA 给证书签名, 并且加密方法保证已经签名的证书是难以计算和伪造的. 所以, 只要 CA 是真实的可信的权威机构, 客户端能更好的保证他们连接到的是可信的机器.
            <pre class="brush: bash;">
            openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</pre>

            生成的 CA 是一个简单的公私密钥对和证书, 然后, 它将对其他证书签名.<br>

            下一步是将生成的 CA 添加到 **客户端的信任存储区 (clients' truststore)**, 这样客户端才可以相信这个 CA:
            <pre class="brush: bash;">
            keytool -keystore client.truststore.jks -alias CARoot -import -file ca-cert</pre>

            <b>Note:</b> 如果你将 Kafka broker 配置成需要客户端授权, 可以在 <a href="#config_broker">Kafka broker 配置</a>中设置 setting ssl.client.auth 属性为 "requested" 或者 "required". 然后你也一定要给 Kafka broker 提供一个信任存储区, 并且这个信任存储区应该拥有所有给客户端密钥签名的 CA 证书.
            <pre class="brush: bash;">
            keytool -keystore server.truststore.jks -alias CARoot -import -file ca-cert</pre>

            相对于第一步中的密钥库 (keystore) 存储每个机器自己的标识, 客户端的信任存储区 (truststore) 保存所有客户端需要信任的证书. 导入一个证书到一台机器的信任存储区, 意味着这台机器将信任所有被这个证书签名的证书. 与上面相似的, 相信政府 (CA) 即相信政府发放的所有护照(证书). 这一特征称为信任链, 当在大型的 Kafka 集群中部署 SSL 时, 这一特征特别有用. 你可以用一个单一的 CA 给集群中的所有证书签名, 而且可以让所有机器共享信任该 CA 的信任存储区. 这样, 每个机器都可以认证除自己之外的全部机器.</li>

        <li><h4><a id="security_ssl_signing" href="#security_ssl_signing">给证书签名</a></h4>
            下一步是用第二步生成的 CA 给第一步生成的所有证书签名. 首先, 你需要从密钥库中把证书导出来: 
            <pre class="brush: bash;">
            keytool -keystore server.keystore.jks -alias localhost -certreq -file cert-file</pre>

            然后用 CA 给导出的证书签名:
            <pre class="brush: bash;">
            openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file -out cert-signed -days {validity} -CAcreateserial -passin pass:{ca-password}</pre>

            最后, 你要把 CA 的证书和被签名的证书一起导入密钥库中:
            <pre class="brush: bash;">
            keytool -keystore server.keystore.jks -alias CARoot -import -file ca-cert
            keytool -keystore server.keystore.jks -alias localhost -import -file cert-signed</pre>

            参数的定义如下所示:
            <ol>
                <li>keystore: 密钥库的地址</li>
                <li>ca-cert: CA 的证书</li>
                <li>ca-key: CA 的私钥</li>
                <li>ca-password: CA 的密码</li>
                <li>cert-file: 从服务器导出的未被签名的证书</li>
                <li>cert-signed: 已经签名的服务器的证书</li>
            </ol>

            这是一个集合上面所有步骤, 用 bash 写的例子. 注意其中一条命令假设密码是 `test1234`, 所以你要么使用这个密码, 要么在执行命令前修改该密码:
            <pre>
            #!/bin/bash
            #Step 1
            keytool -keystore server.keystore.jks -alias localhost -validity 365 -keyalg RSA -genkey
            #Step 2
            openssl req -new -x509 -keyout ca-key -out ca-cert -days 365
            keytool -keystore server.truststore.jks -alias CARoot -import -file ca-cert
            keytool -keystore client.truststore.jks -alias CARoot -import -file ca-cert
            #Step 3
            keytool -keystore server.keystore.jks -alias localhost -certreq -file cert-file
            openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file -out cert-signed -days 365 -CAcreateserial -passin pass:test1234
            keytool -keystore server.keystore.jks -alias CARoot -import -file ca-cert
            keytool -keystore server.keystore.jks -alias localhost -import -file cert-signed</pre></li>

        <li><h4><a id="security_configbroker" href="#security_configbroker">配置 Kafka Broker</a></h4>
            Kafka Broker 支持在多个端口上监听连接.
            我们需要在 server.properties 中配置以下属性, 必须有一个或多个用逗号隔开的值:
            <pre>listeners</pre>

            如果 broker 之间的通信没有启用 SSL (如何启用可参照下文). PLAINTEXT 和 SSL 两个协议都需要提供端口信息.
            <pre class="brush: text;">
            listeners=PLAINTEXT://host.name:port,SSL://host.name:port</pre>

            下面是 broker 端需要的 SSL 的配置:
            <pre class="brush: text;">
            ssl.keystore.location=/var/private/ssl/server.keystore.jks
            ssl.keystore.password=test1234
            ssl.key.password=test1234
            ssl.truststore.location=/var/private/ssl/server.truststore.jks
            ssl.truststore.password=test1234</pre>

            Note: 严格来讲 ssl.truststore.password 是可选配置的, 但是强烈建议配置. 如果没有配置 password, 依然可以访问信任存储区 (truststore), 但是不能进行真实性检查.

            值得考虑的可选配置:
            <ol>
                <li>ssl.client.auth=none ("required" => 客户端授权是必须的, "requested" => 客户端授权是需要的, 但是没有证书依然可以连接. 因为 "requested" 会造成错误的安全感, 而且在客户端配置错误的情况下依然可以连接成功, 所以不鼓励使用.)</li>
                <li>ssl.cipher.suites (可选的). 指定的密码套件, 由授权, 加密, MAC 和密钥交换算法组成, 用于给使用 TLS 或者 SSL 协议的网络协商安全设置. (默认是空的 list)</li>
                <li>ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1 (列出你将要从客户端接收的 SSL 协议. 注意, SSL 已经废弃, 支持 TLS, 并且不建议在生产环境中使用 SSL.)</li>
                <li>ssl.keystore.type=JKS</li>
                <li>ssl.truststore.type=JKS</li>
                <li>ssl.secure.random.implementation=SHA1PRNG</li>
            </ol>
            如果你想 broker 间的通信启用 SSL, 将下面内容添加到 server.properties 文件中(默认是 PLAINTEXT ):
            <pre>
            security.inter.broker.protocol=SSL</pre>

            <p>
            由于一些国家的进口规定, Oracle 的实现限制了默认加密算法的强度. 如果需要更强的算法 (例如, 256 位的 AES 密钥), 必须获得 <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">JCE Unlimited Strength Jurisdiction Policy 文件</a>, 并且在 JDK/JRE 中安装.
            参考 <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/SunProviders.html">JCA Providers 文档</a> 获取更多新.
            </p>

            <p>
            JRE/JDK 将有一个默认的伪随机数生成器 (PRNG), 用于加密操作, 所以没有要求使用 <pre>ssl.secure.random.implementation</pre> 配置 PRNG 的实现.
            但是, 其中某些实现会造成性能问题 (尤其是, Linux 系统的默认选择, <pre>NativePRNG</pre>, 利用了一个全局锁.)
            万一 SSL 连接的性能变成一个问题, 可以考虑, 明确的设置要使用的 PRNG 实现.
            <pre>SHA1PRNG</pre> 实现是非阻塞的, 在高负载 (加上复制消息的流量, 每个 broker 生产消息的速度是 50 MB/sec) 下有非常好的性能表现.
            </p>

            一旦你启动了 broker, 你应该能在 server.log 中看到如下内容:
            <pre>
            with addresses: PLAINTEXT -> EndPoint(192.168.64.1,9092,PLAINTEXT),SSL -> EndPoint(192.168.64.1,9093,SSL)</pre>

            用以下命令可以快速验证服务器的 keystore 和 truststore 是否设置正确:
            <pre>openssl s_client -debug -connect localhost:9093 -tls1</pre> (Note: TLSv1 需要在 ssl.enabled.protocols 中列出)<br>
            在命令的输出中, 你应该能看到服务器的证书:
            <pre>
            -----BEGIN CERTIFICATE-----
            {variable sized random bytes}
            -----END CERTIFICATE-----
            subject=/C=US/ST=CA/L=Santa Clara/O=org/OU=org/CN=Sriharsha Chintalapani
            issuer=/C=US/ST=CA/L=Santa Clara/O=org/OU=org/CN=kafka/emailAddress=test@test.com</pre>
            如果没有显示证书信息, 或者有任何其他错误信息, 那么你的 keystore 设置不正确。</li>

        <li><h4><a id="security_configclients" href="#security_configclients">配置 Kafka 客户端</a></h4>
            只有新的 Kafka Producer 和 Consumer 支持 SSL, 旧的 API 不支持 SSL. Producer 和 Consumer 的 SSL 的配置相同.<br>
            如果在 broker 中不需要客户端授权, 那么下面是最小的配置的例子:
            <pre class="brush: text;">
            security.protocol=SSL
            ssl.truststore.location=/var/private/ssl/client.truststore.jks
            ssl.truststore.password=test1234</pre>

            Note: 严格来讲 ssl.truststore.password 是可选配置的, 但是强烈建议配置. 如果没有配置 password, 依然可以访问 truststore, 但是不能进行真实性检查.

            如果要求客户端授权, 必须像第一步一样创建一个 keystore, 和配置下面这些信息:
            <pre class="brush: text;">
            ssl.keystore.location=/var/private/ssl/client.keystore.jks
            ssl.keystore.password=test1234
            ssl.key.password=test1234</pre>
			
            根据我们的需求和 broker 的配置, 也需要设置其他的配置:
                <ol>
                    <li>ssl.provider (可选的). 用于 SSL 连接的安全提供程序名称. 默认值是 JVM 的默认安全提供程序.</li>
                    <li>ssl.cipher.suites (可选的). 指定的密码套件, 由授权, 加密, MAC 和密钥交换算法组成, 用于给使用 TLS 或者 SSL 协议的网络协商安全设置.</li>
                    <li>ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1. 需要列出至少一个在 broker 端配置的协议</li>
                    <li>ssl.truststore.type=JKS</li>
                    <li>ssl.keystore.type=JKS</li>
                </ol>
    <br>
            使用 console-producer 和 console-consumer 的例子:
            <pre class="brush: bash;">
            kafka-console-producer.sh --broker-list localhost:9093 --topic test --producer.config client-ssl.properties
            kafka-console-consumer.sh --bootstrap-server localhost:9093 --topic test --consumer.config client-ssl.properties</pre>
        </li>
    </ol>
    <h3><a id="security_sasl" href="#security_sasl">7.3 使用SASL实现身份验证</a></h3>

    <ol>
    <li><h4><a id="security_sasl_jaasconfig" href="#security_sasl_jaasconfig">JAAS 的配置</a></h4>
    <p>Kafka 使用Java验证和授权API
    (<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/jaas/JAASRefGuide.html">JAAS</a>)
    来完成 SASL 配置.</p>
        <ol>
        <li><h5><a id="security_jaas_broker"
            href="#security_jaas_broker">Kafka brokers 的 JAAS 的配置</a></h5>

            <p><tt>KafkaServer</tt> 是每一个 KafkaServer/Broker 的 JASS 文件里面的节点名称。
                在这个节点中，提供了用于所有 brokers 之间通信的 SASL 客户端连接的 SASL 配置选项。</p>

            <p><tt>Client</tt> 节点是用于认证 SASL 与 zookeeper 之间的连接。它也允许 brokers 通过设定 zookeeper 节点中 SASL ACL
                来锁定这些节点 从而确定这些节点不被其他 broker 修改。
                在所有的 broker 中都必须使用相同的名称。 如果您想使用 Client 以外名称, 请设置系统属性
                <tt>zookeeper.sasl.clientconfig</tt> 中填写合适的名称
                (<i>e.g.</i>, <tt>-Dzookeeper.sasl.clientconfig=ZkClient</tt>).</p>

            <p>ZooKeeper 使用 "zookeeper" 作为默认的名称. 如果您想改变它的话, 请设置系统属性
            <tt>zookeeper.sasl.client.username</tt> 中填写合适的名称
            (<i>e.g.</i>, <tt>-Dzookeeper.sasl.client.username=zk</tt>).</p></li>

        <li><h5><a id="security_jaas_client"
            href="#security_jaas_client">Kafka clients 的 JAAS 的配置</a></h5>

            <p>Client 通过配置客户端属性 <a href="#security_client_dynamicjaas">sasl.jaas.config</a>
                或者通过与 brokers 相似的方法来配置 JAAS （<a href="#security_client_staticjaas">static JAAS config file</a>）
            </p>

            <ol>
            <li><h6><a id="security_client_dynamicjaas"
                href="#security_client_dynamicjaas">通过客户端配置属性来配置JAAS</a></h6>
                <p>客户无需创建物理文件来配置角色 只需要在 JASS 配置中指定 producer 或者 consumer。
                    这种模式通过为每个客户端指定不同的属性来使用不同的凭证，从而确保可以在在同一个 JVM 中使用不同的 producers
                    和 consumers。如果静态JAAS配置系统属性的方法
                <code>java.security.auth.login.config</code> 和配置客户端属性 <code>sasl.jaas.config</code>的方法
              同时被使用, 客户端的配置将会被使用.</p>
                <p>请看 <a href="#security_sasl_kerberos_clientconfig">GSSAPI (Kerberos)</a>,
                <a href="#security_sasl_plain_clientconfig">PLAIN</a> or
                <a href="#security_sasl_scram_clientconfig">SCRAM</a> 中的示例配置。</p></li>

                <li><h6><a id="security_client_staticjaas" href="#security_client_staticjaas">通过静态配置文件来配置 JAAS</a></h6>
                    使用静态 JAAS 配置文件 来配置 SASL 的客户端认证服务：
                <ol>
                <li>添加一个名为 <tt>KafkaClient</tt> 客户端的登陆节点，同时为 <tt>KafkaClient</tt> 中所选机制来配置一个登陆模块
                    如设置<a href="#security_sasl_kerberos_clientconfig">GSSAPI (Kerberos)</a>,
                    <a href="#security_sasl_plain_clientconfig">PLAIN</a> 或者
                    <a href="#security_sasl_scram_clientconfig">SCRAM</a>。
                    例如, <a href="#security_sasl_gssapi_clientconfig">GSSAPI</a>
                    的凭证配置如下:
                    <pre class="brush: text;">
        KafkaClient {
        com.sun.security.auth.module.Krb5LoginModule required
        useKeyTab=true
        storeKey=true
        keyTab="/etc/security/keytabs/kafka_client.keytab"
        principal="kafka-client-1@EXAMPLE.COM";
    };</pre>
                </li>
                <li>将 JASS 的配置文件位置作为 JVM 的参数传递给每个客户端的 JVM。 例如:
                    <pre class="brush: bash;">    -Djava.security.auth.login.config=/etc/kafka/kafka_client_jaas.conf</pre></li>
	</ol>
                </li>
            </ol>
            </li>
        </ol>
    </li>
    <li><h4><a id="security_sasl_config"
               href="#security_sasl_config">SASL 的配置</a></h4>

        <p> SASL 可以使用 PLAINTEXT 或者 SSL 协议作为传输层，相对应的就是使用 SASL_PLAINTEXT 或者 SASL_SSL 安全协议。
            如果使用 SASL_SSL 安全协议，必须配置 <a href="#security_ssl">SSL证书</a>。</p>

        <ol>
            <li><h5><a id="security_sasl_mechanism"
                       href="#security_sasl_mechanism">SASL 安全机制</a></h5>
                Kafka 支持以下的四个 SASL 机制:
                <ul>
                    <li><a href="#security_sasl_kerberos">GSSAPI</a> (Kerberos)</li>
                    <li><a href="#security_sasl_plain">PLAIN</a></li>
                    <li><a href="#security_sasl_scram">SCRAM-SHA-256</a></li>
                    <li><a href="#security_sasl_scram">SCRAM-SHA-512</a></li>
                </ul>
            </li>
            <li><h5><a id="security_sasl_brokerconfig"
                       href="#security_sasl_brokerconfig">Kafka brokers 的SASL配置</a></h5>
                <ol>
                    <li>在 server.properties 文件中配置一个 SASL 端口， 要为 <i>listeners</i> 添加其中至少一个参数（SASL_PLAINTEXT 或者 SASL_SSL）：
                        <pre>    listeners=SASL_PLAINTEXT://host.name:port</pre>
                        如果您只配置一个 SASL 端口 （或者您只想希望在 Kafka brokersz 之间使用 SASL 协议相互认证的话）您需要确保您在 borker 之间通信中 使用了了相同的 SASL 协议。
                        <pre>    security.inter.broker.protocol=SASL_PLAINTEXT (or SASL_SSL)</pre></li>
                    <li>选择一个或者多个 <a href="#security_sasl_mechanism">支持的安全机制</a>
                        然后按照所给的步骤来为所选的安全机制配置 SASL 协议。 如果您想在 broker 中启用多个安全机制， 请根据<a href="#security_sasl_multimechanism">此处</a>步骤操作。
                </ol>
            </li>
            <li><h5><a id="security_sasl_clientconfig"
                       href="#security_sasl_clientconfig">Kafka 客户端配置 SASL</a></h5>
                <p> SASL 授权只在新的 Java Kafka producer and consumer API 中被支持。之前的API并不支持</p>

                <p>要在客户端配置 SASL 授权， 需在 broker 中选择一个已启用的<a href="#security_sasl_mechanism">SASL 机制</a>用于客户端授权
                    并且根据下面的步骤为所选的安全机制配置 SASL 协议。</p>
            </li>
        </ol>
    </li>
    <li><h4><a id="security_sasl_kerberos" href="#security_sasl_kerberos">使用 SASL/Kerberos 认证协议</a></h4>
        <ol>
        <li><h5><a id="security_sasl_kerberos_prereq" href="#security_sasl_kerberos_prereq">准备条件</a></h5>
        <ol>
            <li><b>Kerberos</b><br>
                如果您的项目已经使用 Kerberos 认证协议服务器（例如使用了Active Directory），那么您就无需为 Kafka 安装新的服务器，否则您需要从您 Linux 社区中的服务包中安装一个。
                此处有一个简短的指南教您如何安装并且配置它(<a href="https://help.ubuntu.com/community/Kerberos">Ubuntu</a>,<a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Managing_Smart_Cards/installing-kerberos.html">Redhat</a>).
                请注意，若果您正在使用 Oracle Java， 您需要对应您的 Java 版本 下载 JCE 策略文件，并且将它拷贝到 $JAVA_HOME/jre/lib/security 路径下面。
            </li>
            <li><b>创建 Kerberos 证书</b><br>
            如果您在使用团队的 Kerberos 服务器或者 Active Directory 服务器, 请向您的 Kerberos 管理员咨询集群中每一个 Kafka broker 的证书 和 每个将通过 Kerberos 身份验证的用户的证书（通过客户端或者工具等方式通过身份验证）。</br>
                如果您已经安装了自己的 Kerberos， 您可以根据下面的步骤为您自己创建证书：
                <pre class="brush: bash;">
        sudo /usr/sbin/kadmin.local -q 'addprinc -randkey kafka/{hostname}@{REALM}'
        sudo /usr/sbin/kadmin.local -q "ktadd -k /etc/security/keytabs/{keytabname}.keytab kafka/{hostname}@{REALM}"</pre></li>
            <li><b>确保所有的主机名可以访问其对应的主机</b> - Kerberos 要求您的所有主机都可以被其 FQDN 进行解析。</li>
        </ol>
        <li><h5><a id="security_sasl_kerberos_brokerconfig" href="#security_sasl_kerberos_brokerconfig">Kafka Brokers 的配置</a></h5>
        <ol>
            <li>为每一个 Kafka broker 的 config 目录下，创建一个类似下面的适当修改的 JAAS 文件，我们在这个例子中把它命名为 kafka_server_jaas.conf
                （请注意每一个 broker 都应该有他自己 keytab):
            <pre class="brush: text;">
        KafkaServer {
            com.sun.security.auth.module.Krb5LoginModule required
            useKeyTab=true
            storeKey=true
            keyTab="/etc/security/keytabs/kafka_server.keytab"
            principal="kafka/kafka1.hostname.com@EXAMPLE.COM";
        };

        // Zookeeper client authentication
        Client {
        com.sun.security.auth.module.Krb5LoginModule required
        useKeyTab=true
        storeKey=true
        keyTab="/etc/security/keytabs/kafka_server.keytab"
        principal="kafka/kafka1.hostname.com@EXAMPLE.COM";
        };</pre>

            </li>
            JAAS 文件中 的 <tt>KafkaServer</tt> 节点 告诉 broker 使用哪一个认证以及对应的认证的 keytab 的位置。
            它允许 broker 根据节点中的 keytab 中的信息来认证登陆。 有关 Zookeeper SASL 配置的更多详细信息，请参阅 <a href="#security_sasl_brokernotes">此处</a>。
            <li>将 JAAS 和 krb5（可选）的文件位置作为 JVM 的参数传给每一个 Kafka broker。获取更多资料请参照 <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/jgss/tutorials/KerberosReq.html">此处</a>。
                <pre>    -Djava.security.krb5.conf=/etc/kafka/krb5.conf
        -Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf</pre>
            </li>
            <li>确保启动 Kafka broker 的操作系统用户可以读取 JAAS 文件中的 keytabs。</li>
            <li>在配置server.properties文件中，确保SASL 端口 和 SASL 安全机制<a href="#security_sasl_brokerconfig">配置</a>正确. 例如:
            <pre>    listeners=SASL_PLAINTEXT://host.name:port
        security.inter.broker.protocol=SASL_PLAINTEXT
        sasl.mechanism.inter.broker.protocol=GSSAPI
        sasl.enabled.mechanisms=GSSAPI
            </pre>
            </li>我们在 server.properties 文件中， 必须配置和 Kafka broker 证书中名称相匹配的服务器名称。
            在下面的例子中， 证书的名称为"kafka/kafka1.hostname.com@EXAMPLE.com"，所以
            <pre>    sasl.kerberos.service.name=kafka</pre>

        </ol></li>
        <li><h5><a id="security_sasl_kerberos_clientconfig" href="#security_kerberos_sasl_clientconfig">Kafka 客户端的配置</a></h5>
            在客户端配置 SASL 认证:
            <ol>
                <li>
                    客户端 (producers, consumers, connect workers, 等等) 将使用自己的证书对集群进行身份验证（证书的名字通常与运行客户端的用户同名）
                    然后根据需要来创建或者获取证书。从而为每一个客户端配置 JAAS 配置属性。
                    通过指定不同的证书， JVM的不同客户端可以作为不同的用户运行。
                    在 producer.properties 或者 consumer.properties 文件中 <code>sasl.jaas.config</code> 属性描述着客户端（producer 或 consumer）通过何种方式连接 Kafka broker。
                    下面的例子是使用 keytab 配置客户端（建议用于长时间运行的进程）：
                <pre>
    sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
        useKeyTab=true \
        storeKey=true  \
        keyTab="/etc/security/keytabs/kafka_client.keytab" \
        principal="kafka-client-1@EXAMPLE.COM";</pre>
                    对于像 kafka-console-consumer 和 kafka-console-producer 这样的命令行应用程序， kinit 可以与 "useTicketCache=true" 一同使用。就像：
                <pre>
    sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
        useTicketCache=true;</pre>

                    客户端的 JAAS 配置 也可以设定为与<a href="#security_client_staticjaas">此处</a>所述的 broker 类似的参数。
                    客户端使用登陆的节点名称(<tt>KafkaClient</tt>)的这个选项只来确保 一个 JVM 的所有的客户端只对应一个用户。</li>
                <li>确保启动 Kafka broker 的操作系统用户可以读取 JAAS 文件中的 keytabs。</li>
                <li>（可选）将 krb5 的文件位置作为 JVM 的参数传给每一个 Kafka broker。获取更多资料请参照<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/jgss/tutorials/KerberosReq.html">此处</a>：
                <pre>    -Djava.security.krb5.conf=/etc/kafka/krb5.conf</pre></li>
                <li>在 producer.properties 和 consumer.properties 文件中配置以下的属性：
                <pre>
    security.protocol=SASL_PLAINTEXT (or SASL_SSL)
    sasl.mechanism=GSSAPI
    sasl.kerberos.service.name=kafka</pre></li>
            </ol>
        </li>
        </ol>
    </li>

    <li><h4><a id="security_sasl_plain" href="#security_sasl_plain">使用 SASL/PLAIN 认证</a></h4>
        <p>SASL/PLAIN 是一种简单的 username/password 认证机制, 通常与 TLS 加密一起使用, 用于实现安全认证.
        Kafka 提供了一个默认的 SASL/PLAIN 实现, 可以做扩展后在生产环境使用, 如 <a href="#security_sasl_plain_production">这里</a> 的描述.</p>
        username 在 ACL 等的配置中作为已认证的 <code>Principal</code>.
        <ol>
        <li><h5><a id="security_sasl_plain_brokerconfig" href="#security_sasl_plain_brokerconfig">配置 Kafka Broker</a></h5>
            <ol>
            <li>在每一个 Kafka broker 的 config 目录中, 添加一个类似于下面的适当修改过的 JAAS 文件. 在这个例子中, 让我们将它命名为 kafka_server_jaas.conf:
                <pre class="brush: text;">
        KafkaServer {
            org.apache.kafka.common.security.plain.PlainLoginModule required
            username="admin"
            password="admin-secret"
            user_admin="admin-secret"
            user_alice="alice-secret";
        };</pre>
                这个配置定义了两个用户 (<i>admin</i> and <i>alice</i>). 
                broker 使用在 <tt>KafkaServer</tt> 部分的 <tt>username</tt> 和 <tt>password</tt> 属性初始化与其他 broker 的连接.
                在这个例子中, <i>admin</i> 是 broker 间通信的用户.
                <tt>user_<i>userName</i></tt> 属性的值定义了所有连接到 broker 的用户的密码.
                这个 broker 验证所有客户端的连接, 包括那些使用了这些配置的 broker 的连接.</li>
            <li>将 JAAS 配置文件的路径作为 JVM 的参数, 并传递到每一个 Kafka broker:
                <pre>    -Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf</pre></li>
            <li>如 <a href="#security_sasl_brokerconfig">这里</a> 描述的, 在 server.properties 中配置 SASL 端口和 SASL 机制. 例如:
                <pre>    listeners=SASL_SSL://host.name:port
        security.inter.broker.protocol=SASL_SSL
        sasl.mechanism.inter.broker.protocol=PLAIN
        sasl.enabled.mechanisms=PLAIN</pre></li>
            </ol>
        </li>

        <li><h5><a id="security_sasl_plain_clientconfig" href="#security_sasl_plain_clientconfig">配置 Kafka Client</a></h5>
            在客户端上配置 SASL 验证:
            <ol>
            <li>在每一个客户端的 producer.properties 或者 consumer.properties 中配置 JAAS 属性.
                登录模块描述了像生产者和消费者这样的客户端如何连接到 Kafka Broker.
                下面是一个 PLAIN 机制的客户端的配置示例:
                <pre class="brush: text;">
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
        username="alice" \
        password="alice-secret";</pre>
                <p><tt>username</tt> 和 <tt>password</tt> 选项被客户端用于配置客户端连接的用户.
                在这个例子中, 客户端以 <i>alice</i> 用户连接到 broker.
                通过在 <code>sasl.jaas.config</code> 中指定不同的用户名和密码, 在一个 JVM 内不同的客户端可以以不同的用户连接.</p>

                <p>客户端的 JAAS 配置也可以像 <a href="#security_client_staticjaas">这里</a> 描述的 broker 一样, 指定为一个 JVM 参数.
                客户端使用名为 <tt>KafkaClient</tt> 的登录部分.
                此选项仅允许来自 JVM 的所有客户端连接中的一个用户.</p></li>
            <li>在 producer.properties 或者 consumer.properties 中配置下面这些属性:
                <pre>
    security.protocol=SASL_SSL
    sasl.mechanism=PLAIN</pre></li>
            </ol>
        </li>
        <li><h5><a id="security_sasl_plain_production" href="#security_sasl_plain_production">在生产环境中使用 SASL/PLAIN</a></h5>
            <ul>
            <li>SASL/PLAIN 应该只用 SSL 作为传输层, 以保证在没有加密的情况下不会在线上传输明文密码.</li>
            <li>Kafka 中 SASL/PLAIN 的默认实现是在 JAAS 配置文件声明用户名和密码, 如 <a href="#security_sasl_plain_brokerconfig">这里</a> 展示的. 
                为了避免在磁盘上保存密码, 你可以实现你自己的 <code>javax.security.auth.spi.LoginModule</code>, 从一个外部源提供用户名和密码.
                登录模块的实现应该提供 <code>Subject</code> 的用户名作为公共证书和密码作为私有的凭证.
                <code>org.apache.kafka.common.security.plain.PlainLoginModule</code> 的默认实现可以作为参考例子.</li>
            <li>在生产系统, 外部的认证服务可以实现密码认证. 通过添加你自己的 <code>javax.security.sasl.SaslServer</code> 实现, Kafka brokers 可以和这些服务集成.
                Kafka 中的默认实现在 <code>org.apache.kafka.common.security.plain</code> 包中, 可以作为开始学习的例子.
                <ul>
                <li>新的提供者一定要在 JVM 中安装和注册. 可以通过添加提供类到平常的 <tt>CLASSPATH</tt>, 或者把提供类打包成 jar 文件并添加到<tt><i>JAVA_HOME</i>/lib/ext</tt>中来安装提供者.</li>
                <li>将提供者添加到安全属性文件 (security properties file) <tt><i>JAVA_HOME</i>/lib/security/java.security</tt> 静态注册提供者.
                <pre>    security.provider.n=providerClassName</pre>
                其中 <i>providerClassName</i> 是新提供者的全称. <i>n</i> 是优先顺序, 比较小的数字表明更高的优先级.</li>
                <li>此外, 你可以在运行时通过在客户端程序开始时或者在登录模块的一个静态初始化程序中唤起 <code>Security.addProvider</code>来动态的注册提供者. 例如:
                <pre>    Security.addProvider(new PlainSaslServerProvider());</pre></li>
                <li>更多细节, 请查看 <a href="http://docs.oracle.com/javase/8/docs/technotes/guides/security/crypto/CryptoSpec.html">JCA Reference</a>.</li>
                </ul>
            </li>
            </ul>
        </li>
        </ol>
    </li>

    <li><h4><a id="security_sasl_scram" href="#security_sasl_scram">使用 SASL/SCRAM 认证</a></h4>
        <p>Salted Challenge Response Authentication Mechanism (SCRAM) 是 SASL 机制家族中的一员, 
        是用传统的机制解决安全问题, 执行像 PLAIN 和 DIGEST-MD5 一样的 username/password 认证.
        这个机制在 <a href="https://tools.ietf.org/html/rfc5802">RFC 5802</a> 定义.
        Kafka 支持 <a href="https://tools.ietf.org/html/rfc7677">SCRAM-SHA-256</a> 和 SCRAM-SHA-512, 可以和 TLS 一起用户执行安全认证.
        username 在 ACL 等的配置中作为已认证的 <code>Principal</code>.
        Kafka 中默认的 SCRAM 实现是在 Zookeeper 中保存 SCRAM 证书, 适用于 Zookeeper 在私有网络的 Kafka 安装.
        更多信息请查看 <a href="#security_sasl_scram_security">安全注意事项</a>.</p>
        <ol>
        <li><h5><a id="security_sasl_scram_credentials" href="#security_sasl_scram_credentials">创建 SCRAM 证书</a></h5>
        <p>Kafka 中的 SCRAM 实现使用 Zookeeper 作为证书存储. 可以使用 <tt>kafka-configs.sh</tt> 在 Zookeeper 中创建证书.
        对每一个启用了 SCRAM 机制的, 必须通过添加机制名配置来创建证书. 用于 broker 间通信的证书必须在 Kafka broker 启动前创建.
        客户端的证书可以动态创建和更新, 新的连接使用更新后的证书认证.</p>
        <p>为用户 <i>alice</i> 创建密码为 <i>alice-secret</i> 的 SCRAM 凭证:
        <pre class="brush: bash;">
    > bin/kafka-configs.sh --zookeeper localhost:2181 --alter --add-config 'SCRAM-SHA-256=[iterations=8192,password=alice-secret],SCRAM-SHA-512=[password=alice-secret]' --entity-type users --entity-name alice
        </pre>
        <p>如果未指定迭代次数, 将使用默认的迭代次数, 4096. 创建一个随机 salt, SCRAM 标识由 salt, 迭代和 StoredKey 组成.
        ServerKey 保存在 Zookeeper 中.
        有关 SCRAM 的标识和各个字段的详细信息，请参考 <a href="https://tools.ietf.org/html/rfc5802">RFC 5802</a>.
        <p>以下示例中, 关于 broker 间的通信, 需要一个 <i>admin</i> 用户. 使用如下命令创建:
        <pre class="brush: bash;">
    > bin/kafka-configs.sh --zookeeper localhost:2181 --alter --add-config 'SCRAM-SHA-256=[password=admin-secret],SCRAM-SHA-512=[password=admin-secret]' --entity-type users --entity-name admin
        </pre>
        <p>使用 <i>--describe</i> 选项可以 列出所有存在的证书:
        <pre class="brush: bash;">
    > bin/kafka-configs.sh --zookeeper localhost:2181 --describe --entity-type users --entity-name alice
        </pre>
        <p>使用 <i>--delete</i> 选项删除一个或多个 SCRAM 机制的证书:
        <pre class="brush: bash;">
    > bin/kafka-configs.sh --zookeeper localhost:2181 --alter --delete-config 'SCRAM-SHA-512' --entity-type users --entity-name alice
        </pre>
        </li>
        <li><h5><a id="security_sasl_scram_brokerconfig" href="#security_sasl_scram_brokerconfig">配置 Kafka Broker</a></h5>
            <ol>
            <li>在每个 Kafka broker 的 config 目录, 添加一个类似下面的适当修改的 JAAS 文件. 在这个例子中, 我们将其命名为 kafka_server_jaas.conf:
                <pre>
    KafkaServer {
        org.apache.kafka.common.security.scram.ScramLoginModule required
        username="admin"
        password="admin-secret";
    };</pre>
                broker 使用 <tt>KafkaServer</tt> 部分中 <tt>username</tt> 和 <tt>password</tt> 属性来初始化与其他 broker 的连接.
                在这个例子中, <i>admin</i> 是 broker 间通信的用户.</li>
            <li>JAAS 配置文件的路径作为 JVM 参数传递给每个 Kafka broker:
                <pre>    -Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf</pre></li>
            <li>参考 <a href="#security_sasl_brokerconfig">这里</a> 的描述, 在 server.properties 配置 SASL 端口和 SASL 机制. 例如:
                <pre>
    listeners=SASL_SSL://host.name:port
    security.inter.broker.protocol=SASL_SSL
    sasl.mechanism.inter.broker.protocol=SCRAM-SHA-256 (or SCRAM-SHA-512)
    sasl.enabled.mechanisms=SCRAM-SHA-256 (or SCRAM-SHA-512)</pre></li>
            </ol>
        </li>

        <li><h5><a id="security_sasl_scram_clientconfig" href="#security_sasl_scram_clientconfig">配置 Kafka Client</a></h5>
            To configure SASL authentication on the clients:
            在客户端配置 SASL 认证:
            <ol>
	    <li>在每个客户端的 producer.properties 或者 consumer.properties 文件中配置 JAAS 配置项.
            登录模块描述了像生产者和消费者这样的客户端如何连接到 Kafka Broker.
            下面是一个 SCRAM 机制的客户端的配置示例:
                <pre class="brush: text;">
   sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
        username="alice" \
        password="alice-secret";</pre>

                <p><tt>username</tt> 和 <tt>password</tt> 选项被客户端用于配置客户端连接的用户信息. 
                    在这个例子中, 客户端作为 <i>alice</i> 用户连接到 broker.
                    通过在 <code>sasl.jaas.config</code> 中指定不同的用户名和密码, 在一个 JVM 内不同的客户端可以根据不同的用户连接.</p>

                <p>客户端的 JAAS 配置也可以像 broker <a href="#security_client_staticjaas">这里</a> 描述的一样, 指定为一个 JVM 参数.
                客户端使用命名为 <tt>KafkaClient</tt> 的登录部分.
                此选项仅允许来自 JVM 的所有客户端连接中的一个用户.</p></li>
            <li>在 producer.properties 或者 consumer.properties 中配置下面这些属性:
                <pre>
    security.protocol=SASL_SSL
    sasl.mechanism=SCRAM-SHA-256 (or SCRAM-SHA-512)</pre></li>
            </ol>
        </li>
        <li><h5><a id="security_sasl_scram_security" href="#security_sasl_scram_security">SASL/SCRAM 的安全注意事项</a></h5>
            <ul>
            <li>Kafka 中 SASL/SCRAM 的默认实现在 Zookeeper 中保存 SCRAM 证书. 这个适合当 Zookeeper 是安全并且是在私有网络时, 在生产环境安装.</li>
            <li>Kafka 只支持强散列函数 SHA-256 和 SHA-512, 和最小迭代数为4096. 如果 Zookeeper 安全性收到威胁, 强散列函数结合强密码, 高迭代次数可以防止暴力攻击.</li>
            <li>SCRAM 应只使用 TLS 加密, 防止 SCRAM 交换时的中途拦截. 如果 Zookeeper 受到威胁, 这可以防止字典或者暴力攻击, 和防止伪装模拟.</li>
            <li>当 Zookeeper 不安全是, SASL/SCRAM 的默认实现可以在安装时使用自定义的登录模块重写. 更多细节查看 <a href="#security_sasl_plain_production">这里</a>.</li>
            <li>了解安全注意事项的更多细节, 参考 <a href="https://tools.ietf.org/html/rfc5802#section-9">RFC 5802</a>.
            </ul>
        </li>
        </ol>
    </li>

    <li><h4><a id="security_sasl_multimechanism" href="#security_sasl_multimechanism">Enabling multiple SASL mechanisms in a broker（broker 节点上启用多个 SASL 机制                       ）</a></h4>
        <ol>
        <li>在JAAS配置文件的<tt>KafkaServer</tt> 部分中指定所有启用机制的登录模块的配置。例如：
            <pre>
        KafkaServer {
            com.sun.security.auth.module.Krb5LoginModule required
            useKeyTab=true
            storeKey=true
            keyTab="/etc/security/keytabs/kafka_server.keytab"
            principal="kafka/kafka1.hostname.com@EXAMPLE.COM";

            org.apache.kafka.common.security.plain.PlainLoginModule required
            username="admin"
            password="admin-secret"
            user_admin="admin-secret"
            user_alice="alice-secret";
        };</pre></li>
        <li>在 server.properties 配置文件中启用 SASL 机制： <pre>    sasl.enabled.mechanisms=GSSAPI,PLAIN,SCRAM-SHA-256,SCRAM-SHA-512</pre></li>
        <li>如果需要，可以在 server.properties 中指定 SASL 安全协议和 broker 间的通信机制：
            <pre>
    security.inter.broker.protocol=SASL_PLAINTEXT (or SASL_SSL)
    sasl.mechanism.inter.broker.protocol=GSSAPI (or one of the other enabled mechanisms)</pre></li>
        <li>遵循 <a href="#security_sasl_kerberos_brokerconfig">GSSAPI (Kerberos)</a>、
            <a href="#security_sasl_plain_brokerconfig"> PLAIN </a> 和 <a href="#security_sasl_scram_brokerconfig">SCRAM</a>
            特定的步骤来配置启用 SASL 机制。</li>
        </ol>
    </li>
    <li><h4><a id="saslmechanism_rolling_upgrade" href="#saslmechanism_rolling_upgrade">Modifying SASL mechanism in a Running Cluster（在运行的集群里修改 SASL 机制）</a></h4>
        <p>按照下面的步骤可以修改正在运行中的集群的 SASL 机制：</p>
        <ol>
        <li>为了给每个 broker 启用新的 SASL 机制，需要在 server.properties 中添加 <tt>sasl.enabled.mechanisms</tt> 配置。更新 <a href="#security_sasl_multimechanism">这里</a>描述的两种机制到JAAS配置文件。
            依次更新每个集群节点</li>
        <li>使用新机制重新启动客户端。</li>
        <li>如果有必要，可以在 server.properties 文件中指定新的<tt>sasl.mechanism.inter.broker.protocol</tt>的配置，来修改 broker 间的通信机制。然后再次依次的更新集群。
            </li>
        <li>如果有必要，可以从 server.properties 文件中的<tt>sasl.enabled.mechanisms</tt> 配置中和 JAAS 配置文件中删除旧的机制条目，来删除旧的机制。
            然后再次依次的更新集群。</li>
        </ol>
    </li>
    </ol>

    <h3><a id="security_authz" href="#security_authz">7.4 Authorization and ACLs(授权和访问控制列表)</a></h3>
    Kafka 带有一个可扩展的 Authorizer (授权器) 和一个用 zookeeper 实现的 Authorizer (授权器)，zookeeper 会存储所有的 acls 授权信息。 Kafka acls 授权信息定义的规则是 " P is [Allowed/Denied] Operation O From Host H On Resource R"。您可以在KIP-11上阅读更多关于 acl 结构信息。您可以通过Kafka认证器(authorizer)的CLI对acls进行添加、删除或查询。默认情况下，如果资源R没有关联acls 授权信息，那么除超级用户以外的任何人都不能访问资源R。如果要更改该行为，你可以在server.properties 文件中填写以下内容。
    <pre>allow.everyone.if.no.acl.found=true</pre>
    还可以在server.properties中添加超级用户，如下所示（请注意，由于SSL用户名可能包含逗号，因此分隔符是分号）
    <pre>super.users=User:Bob;User:Alice</pre>
    默认情况下，SSL用户名的格式为："CN=writeuser,OU=Unknown,O=Unknown,L=Unknown,ST=Unknown,C=Unknown"。可以通过在server.properties中设置一个自定义的PrincipalBuilder来改变这种情况，如下所示。
    <pre>principal.builder.class=CustomizedPrincipalBuilderClass</pre>
    默认情况下，SASL用户名将成为Kerberos主体的主要部分。有一种方式可以改变，通过设置 <code>sasl.kerberos.principal.to.local.rules</code> 在server.properties中自定义规则。
    <code>sasl.kerberos.principal.to.local.rules</code>是一个列表，其中每个规则的工作方式与<a href="http://web.mit.edu/Kerberos/krb5-latest/doc/admin/conf_files/krb5_conf.html">Kerberos configuration file (krb5.conf)</a>中的auth_to_local相同。每一个规则以 RULE: 开始，并且包含一个格式为[n:string](regexp)s/pattern/replacement/g的表达式。请查看kerberos文档获取更多细节。下面是添加一个规则的示例，该示例可以很正确地翻译user@MYDOMAIN.COM。并让user同时保持默认的规则:
    <pre>sasl.kerberos.principal.to.local.rules=RULE:[1:$1@$0](.*@MYDOMAIN.COM)s/@.*//,DEFAULT</pre>

    <h4><a id="security_authz_cli" href="#security_authz_cli">Command Line Interface(命令行界面) </a></h4>
    Kafka的授权管理CLI(命令行界面)可以在bin目录下找到，并使用所有其他CLIs。命令行界面脚本的名字是 <b>kafka-acls.sh</b>。以下列出了脚本支持的所有选项：
    <p></p>
    <table class="data-table">
        <tr>
            <th>选项</th>
            <th>说明</th>
            <th>默认值</th>
            <th>选项类型</th>
        </tr>
        <tr>
            <td>--add</td>
            <td>表示用户正在尝试添加acl的脚本</td>
            <td></td>
            <td>Action</td>
        </tr>
        <tr>
            <td>--remove</td>
            <td>表示用户正在尝试删除acl的脚本。</td>
            <td></td>
            <td>Action</td>
        </tr>
        <tr>
            <td>--list</td>
            <td>表示用户正在尝试列出acls的脚本。</td>
            <td></td>
            <td>Action</td>
        </tr>
        <tr>
            <td>--authorizer</td>
            <td>授权器的完全限定类名。</td>
            <td>kafka.security.auth.SimpleAclAuthorizer</td>
            <td>Configuration</td>
        </tr>
        <tr>
            <td>--authorizer-properties</td>
            <td>键值对(key=val)将被传递给授权器进行初始化。对于默认授权器，示例值为：zookeeper.connect = localhost：2181</td>
            <td></td>
            <td>Configuration</td>
        </tr>
        <tr>
            <td>--cluster</td>
            <td>指定一个集群作为资源。</td>
            <td></td>
            <td>Resource</td>
        </tr>
        <tr>
            <td>--topic [topic-name]</td>
            <td>指定一个topic(主题)作为资源。</td>
            <td></td>
            <td>Resource</td>
        </tr>
        <tr>
            <td>--group [group-name]</td>
            <td>指定consumer-group(消费组)作为资源。</td>
            <td></td>
            <td>Resource</td>
        </tr>
        <tr>
            <td>--allow-principal</td>
            <td>Principal(委托人)是PrincipalType:name的格式，将被添加到ACL中并有允许权限。<br>你可以在单个命令中指定多个 --allow-principal。</td>
            <td></td>
            <td>Principal</td>
        </tr>
        <tr>
            <td>--deny-principal</td>
            <td>Principal是PrincipalType:name格式，将被添加到ACL中并有拒绝权限。<br>你可以在单个命令中指定多个--deny-principal。</td>
            <td></td>
            <td>Principal</td>
        </tr>
        <tr>
            <td>--allow-host</td>
            <td>在--allow-principal中列出将允许principal从哪些IP地址访问。</td>
            <td>如果指定 --allow-principal的默认值为 *，将允许从所有主机进行访问。</td>
            <td>Host</td>
        </tr>
        <tr>
            <td>--deny-host</td>
            <td>在--deny-principal中列出将拒绝principal从哪些IP地址访问。</td>
            <td>如果指定 --deny-principal的默认值为 *，将允许从所有主机进行访问。</td>
            <td>Host</td>
        </tr>
        <tr>
            <td>--operation</td>
            <td>将会被允许和拒绝的操作<br>
                有效值: Read(读), Write(写), Create(创建), Delete(删除), Alter(修改), Describe(描述), ClusterAction(集群操作), All(所有)</td>
            <td>All</td>
            <td>Operation</td>
        </tr>
        <tr>
            <td>--producer</td>
            <td> 该选项可为生产者添加和删除acls(访问控制列表)。它生成的acls允许在topic(主题)上进行WRITE,
                DESCRIBE操作，并且在集群上进行CREATE操作。</td>
            <td></td>
            <td>Convenience</td>
        </tr>
        <tr>
            <td>--consumer</td>
            <td> 该选项可为消费者添加和删除acls(访问控制列表)。 它生成的acls允许在topic(主题)上进行READ,
                DESCRIBE操作，并且通过消费组进行READ操作。</td>
            <td></td>
            <td>Convenience</td>
        </tr>
        <tr>
            <td>--force</td>
            <td> 该选项对所有的查询都假设为yes，并且不提示。</td>
            <td></td>
            <td>Convenience</td>
        </tr>
    </tbody></table>

    <h4><a id="security_authz_examples" href="#security_authz_examples">Examples(例子)</a></h4>
    <ul>
        <li><b>Adding Acls</b><br>
            如果您想添加一个 acl 授权信息 "允许 User:Bob 和 User:Alice 从 IP 198.51.100.0 和 198.51.100.1 对 Topic 中的 Test-Topic 进行读写"。您可以按照下面的选项在终端执行 CLI :
            <pre class="brush: bash;">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic</pre>
            默认情况下，所有的没有显示声明 acl 授权信息的用户，对某个资源操作时都将被拒绝。在极少情况下，我们需要在acl 授权信息定义一个少数用户不允许访问，其他用户都允许访问的规则，这个时候就需要使用 --deny-principal 和 --deny-host 选项。如果我们想允许所有用户对 Test-topic 进行读取，仅拒绝 User:BadBob 从 IP 198.51.100.3 进行读取。我们可以使用下面的命令：
            <pre class="brush: bash;">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:* --allow-host * --deny-principal User:BadBob --deny-host 198.51.100.3 --operation Read --topic Test-topic</pre>
            Note that ``--allow-host`` and ``deny-host`` only support IP addresses (hostnames are not supported).
            注意：``--allow-host`` 和 ``deny-host`` 只支持 IP地址(不支持主机名)
            以上示例通过--topic [topic-name]指定资源选项来将acls添加到 topic 上。同样，用户可以通过指定 --cluster 将 acls 添加到 cluster；通过指定 --group [group-name] 将 acls 添加到一个 consumer group。</li>

        <li><b>Removing Acls</b><br>
                移除 acl 授权信息几乎是相同的命令。唯一的不同就是必须使用 --remove 选项来代替 --add 选项。为了移除上面第一个示例添加的 acls 授权信息，我们可以用 CLI 终端执行下面的选项：
            <pre class="brush: bash;"> bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --remove --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic </pre></li>

        <li><b>List Acls</b><br>
                我们可以通过指定 --list 选项和资源来列出任何资源的 acls 授权信息。如果我们想列出 Test-topic 的所有的 acls授权信息,我们可以用 CLI 终端执行下面的选项：
                <pre class="brush: bash;">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --list --topic Test-topic</pre></li>

        <li><b>Adding or removing a principal as producer or consumer</b><br>
                ACL 管理最常见的情况就是添加或移除一个用户作为 producer 或 consumer。因此我们添加方便的选项来处理这些情景。为了添加 User:Bob 作为 Test-topic 的 producer 我们可以执行下面的命令：
            <pre class="brush: bash;"> bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --producer --topic Test-topic</pre>
            类似的，如果要添加 Alice 到 consumer group Group-1 中作为 Test-topic 的一个 consumer，我们仅需要传递 --consumer 选项：
            <pre class="brush: bash;"> bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --consumer --topic Test-topic --group Group-1 </pre>
                注意：对于 consumer 选项我们必须指定 consumer group。
                为了从 producer 和 consumer 的角色中移除一个用户我们仅需要传 --remove 选项</li>
        </ul>

    <h3><a id="security_rolling_upgrade" href="#security_rolling_upgrade">7.5 Incorporating Security Features in a Running Cluster</a></h3>
        You can secure a running cluster via one or more of the supported protocols discussed previously. This is done in phases:
        <p></p>
        <ul>
            <li>Incrementally bounce the cluster nodes to open additional secured port(s).</li>
            <li>Restart clients using the secured rather than PLAINTEXT port (assuming you are securing the client-broker connection).</li>
            <li>Incrementally bounce the cluster again to enable broker-to-broker security (if this is required)</li>
            <li>A final incremental bounce to close the PLAINTEXT port.</li>
        </ul>
        <p></p>
        The specific steps for configuring SSL and SASL are described in sections <a href="#security_ssl">7.2</a> and <a href="#security_sasl">7.3</a>.
        Follow these steps to enable security for your desired protocol(s).
        <p></p>
        The security implementation lets you configure different protocols for both broker-client and broker-broker communication.
        These must be enabled in separate bounces. A PLAINTEXT port must be left open throughout so brokers and/or clients can continue to communicate.
        <p></p>

        When performing an incremental bounce stop the brokers cleanly via a SIGTERM. It's also good practice to wait for restarted replicas to return to the ISR list before moving onto the next node.
        <p></p>
        As an example, say we wish to encrypt both broker-client and broker-broker communication with SSL. In the first incremental bounce, a SSL port is opened on each node:
            <pre>
            listeners=PLAINTEXT://broker1:9091,SSL://broker1:9092
            </pre>

        We then restart the clients, changing their config to point at the newly opened, secured port:

            <pre>
            bootstrap.servers = [broker1:9092,...]
            security.protocol = SSL
            ...etc
            </pre>

        In the second incremental server bounce we instruct Kafka to use SSL as the broker-broker protocol (which will use the same SSL port):

            <pre>
            listeners=PLAINTEXT://broker1:9091,SSL://broker1:9092
            security.inter.broker.protocol=SSL
            </pre>

        In the final bounce we secure the cluster by closing the PLAINTEXT port:

            <pre>
            listeners=SSL://broker1:9092
            security.inter.broker.protocol=SSL
            </pre>

        Alternatively we might choose to open multiple ports so that different protocols can be used for broker-broker and broker-client communication. Say we wished to use SSL encryption throughout (i.e. for broker-broker and broker-client communication) but we'd like to add SASL authentication to the broker-client connection also. We would achieve this by opening two additional ports during the first bounce:

            <pre>
            listeners=PLAINTEXT://broker1:9091,SSL://broker1:9092,SASL_SSL://broker1:9093
            </pre>

        We would then restart the clients, changing their config to point at the newly opened, SASL & SSL secured port:

            <pre>
            bootstrap.servers = [broker1:9093,...]
            security.protocol = SASL_SSL
            ...etc
            </pre>

        The second server bounce would switch the cluster to use encrypted broker-broker communication via the SSL port we previously opened on port 9092:

            <pre>
            listeners=PLAINTEXT://broker1:9091,SSL://broker1:9092,SASL_SSL://broker1:9093
            security.inter.broker.protocol=SSL
            </pre>

        The final bounce secures the cluster by closing the PLAINTEXT port.

            <pre>
        listeners=SSL://broker1:9092,SASL_SSL://broker1:9093
        security.inter.broker.protocol=SSL
            </pre>

        ZooKeeper can be secured independently of the Kafka cluster. The steps for doing this are covered in section <a href="#zk_authz_migration">7.6.2</a>.


    <h3><a id="zk_authz" href="#zk_authz">7.6 ZooKeeper Authentication</a></h3>
    <h4><a id="zk_authz_new" href="#zk_authz_new">7.6.1 New clusters</a></h4>
    To enable ZooKeeper authentication on brokers, there are two necessary steps:
    <ol>
        <li> Create a JAAS login file and set the appropriate system property to point to it as described above</li>
        <li> Set the configuration property <tt>zookeeper.set.acl</tt> in each broker to true</li>
    </ol>

    The metadata stored in ZooKeeper for the Kafka cluster is world-readable, but can only be modified by the brokers. The rationale behind this decision is that the data stored in ZooKeeper is not sensitive, but inappropriate manipulation of that data can cause cluster disruption. We also recommend limiting the access to ZooKeeper via network segmentation (only brokers and some admin tools need access to ZooKeeper if the new Java consumer and producer clients are used).

    <h4><a id="zk_authz_migration" href="#zk_authz_migration">7.6.2 Migrating clusters</a></h4>
    If you are running a version of Kafka that does not support security or simply with security disabled, and you want to make the cluster secure, then you need to execute the following steps to enable ZooKeeper authentication with minimal disruption to your operations:
    <ol>
        <li>Perform a rolling restart setting the JAAS login file, which enables brokers to authenticate. At the end of the rolling restart, brokers are able to manipulate znodes with strict ACLs, but they will not create znodes with those ACLs</li>
        <li>Perform a second rolling restart of brokers, this time setting the configuration parameter <tt>zookeeper.set.acl</tt> to true, which enables the use of secure ACLs when creating znodes</li>
        <li>Execute the ZkSecurityMigrator tool. To execute the tool, there is this script: <tt>./bin/zookeeper-security-migration.sh</tt> with <tt>zookeeper.acl</tt> set to secure. This tool traverses the corresponding sub-trees changing the ACLs of the znodes</li>
    </ol>
    <p>It is also possible to turn off authentication in a secure cluster. To do it, follow these steps:</p>
    <ol>
        <li>Perform a rolling restart of brokers setting the JAAS login file, which enables brokers to authenticate, but setting <tt>zookeeper.set.acl</tt> to false. At the end of the rolling restart, brokers stop creating znodes with secure ACLs, but are still able to authenticate and manipulate all znodes</li>
        <li>Execute the ZkSecurityMigrator tool. To execute the tool, run this script <tt>./bin/zookeeper-security-migration.sh</tt> with <tt>zookeeper.acl</tt> set to unsecure. This tool traverses the corresponding sub-trees changing the ACLs of the znodes</li>
        <li>Perform a second rolling restart of brokers, this time omitting the system property that sets the JAAS login file</li>
    </ol>
    Here is an example of how to run the migration tool:
    <pre class="brush: bash;">
    ./bin/zookeeper-security-migration.sh --zookeeper.acl=secure --zookeeper.connect=localhost:2181
    </pre>
    <p>Run this to see the full list of parameters:</p>
    <pre class="brush: bash;">
    ./bin/zookeeper-security-migration.sh --help
    </pre>
    <h4><a id="zk_authz_ensemble" href="#zk_authz_ensemble">7.6.3 Migrating the ZooKeeper ensemble</a></h4>
    It is also necessary to enable authentication on the ZooKeeper ensemble. To do it, we need to perform a rolling restart of the server and set a few properties. Please refer to the ZooKeeper documentation for more detail:
    <ol>
        <li><a href="http://zookeeper.apache.org/doc/r3.4.9/zookeeperProgrammers.html#sc_ZooKeeperAccessControl">Apache ZooKeeper documentation</a></li>
        <li><a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zookeeper+and+SASL">Apache ZooKeeper wiki</a></li>
    </ol>
</script>

<div class="p-security"></div>
