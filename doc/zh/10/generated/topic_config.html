<table class="data-table"><tbody>
<tr>
<th>名称</th>
<th>描述</th>
<th>类型</th>
<th>默认值</th>
<th>有效值</th>
<th>服务器默认属性</th>
<th>重要性</th>
</tr>
<tr>
<td>cleanup.policy</td><td>一个字符串，可以是 "delete" 或 "compact"。 此字符串指定在旧日志段上使用的保留策略。 默认策略 ("delete") 将在达到保留时间或大小限制时丢弃旧段。 "compact" 设置将启用该topic <a href="#compaction">日志压缩</a> 。</td><td>list</td><td>delete</td><td>[compact, delete]</td><td>log.cleanup.policy</td><td>medium</td></tr>
<tr>
<td>compression.type</td><td>指定给定topic的最终压缩类型。这个配置接受标准的压缩编解码器 ('gzip', 'snappy', lz4) 。它另外接受相当于不压缩的 'uncompressed' 和 'producer'，这意味着保留producer设置的原始压缩编解码器。</td><td>string</td><td>producer</td><td>[uncompressed, snappy, lz4, gzip, producer]</td><td>compression.type</td><td>medium</td></tr>
<tr>
<td>delete.retention.ms</td><td>保留 <a href="#compaction">日志压缩</a> topics的删除墓碑标记的时间。此设置还对consumer从偏移量0开始时必须完成读取的时间进行限制，以确保它们获得最后阶段的有效快照(否则，在完成扫描之前可能会收集到删除墓碑)。</td><td>long</td><td>86400000</td><td>[0,...]</td><td>log.cleaner.delete.retention.ms</td><td>medium</td></tr>
<tr>
<td>file.delete.delay.ms</td><td>删除文件系统上的一个文件之前所需等待的时间。</td><td>long</td><td>60000</td><td>[0,...]</td><td>log.segment.delete.delay.ms</td><td>medium</td></tr>
<tr>
<td>flush.messages</td><td>这个设置允许指定一个时间间隔，在这个时间间隔中我们将强制执行一个写入日志的数据的fsync。例如，如果这个设置为1，我们会在每条消息之后同步。如果是5，我们会在每五个消息之后进行fsync。一般来说，我们建议您不要设置它，而是通过使用复制来提高耐久性，并且允许操作系统使用后台刷新功能，因为它更高效。这个设置可以在每个topic的基础上被覆盖 (请参阅 <a href="#topicconfigs">每个topic的配置部分</a>).</td><td>long</td><td>9223372036854775807</td><td>[0,...]</td><td>log.flush.interval.messages</td><td>medium</td></tr>
<tr>
<td>flush.ms</td><td>这个设置允许指定一个时间间隔，在这个时间间隔中我们将强制执行一个写入日志的数据的fsync。例如，如果这个设置为1000，我们将在1000 ms后通过fsync。一般来说，我们建议您不要设置它，而是通过使用复制来提高耐久性，并且允许操作系统使用后台刷新功能，因为它更高效。</td><td>long</td><td>9223372036854775807</td><td>[0,...]</td><td>log.flush.interval.ms</td><td>medium</td></tr>
<tr>
<td>follower.replication.throttled.replicas</td><td>应该在follower侧限制日志复制的副本列表。该列表应以[PartitionId]：[BrokerId]，[PartitionId]：[BrokerId]：...的形式描述一组副本，或者也可以使用通配符“*”来限制该topic的所有副本。</td><td>list</td><td>""</td><td>[partitionId],[brokerId]:[partitionId],[brokerId]:...</td><td>follower.replication.throttled.replicas</td><td>medium</td></tr>
<tr>
<td>index.interval.bytes</td><td>此设置控制Kafka向其偏移索引添加索引条目的频率。默认设置确保我们大约每4096个字节索引一条消息。更多的索引允许读取更接近日志中的确切位置，但这会使索引更大。你可能不需要改变这个参数。</td><td>int</td><td>4096</td><td>[0,...]</td><td>log.index.interval.bytes</td><td>medium</td></tr>
<tr>
<td>leader.replication.throttled.replicas</td><td>应该在leader侧限制日志复制的副本列表。该列表应以[PartitionId]：[BrokerId]，[PartitionId]：[BrokerId]：...的形式描述一组副本，或者也可以使用通配符“*”来限制该topic的所有副本。</td><td>list</td><td>""</td><td>[partitionId],[brokerId]:[partitionId],[brokerId]:...</td><td>leader.replication.throttled.replicas</td><td>medium</td></tr>
<tr>
<td>max.message.bytes</td><td><p>Kafka允许的一个批次最大消息量。如果这个参数被增加了且consumers是早于0.10.2版本，那么consumers的fetch size必须增加到该值，以便他们可以取得这么大的记录批次。 </p><p>在最新的消息格式版本中，记录总是分组成多个批次以提高效率。在以前的消息格式版本中，未压缩的记录不会分组到多个批次，并且限制在该情况下只能应用单条记录。</p></td><td>int</td><td>1000012</td><td>[0,...]</td><td>message.max.bytes</td><td>medium</td></tr>
<tr>
<td>message.format.version</td><td>指定broker将用于将消息附加到日志的消息格式版本。该值应该是有效的ApiVersion。一些例子是：0.8.2，0.9.0.0，0.10.0，查看ApiVersion获取更多细节。通过设置特定的消息格式版本，用户将证明磁盘上的所有现有消息都小于或等于指定的版本。不正确地设置此值将导致旧版本的使用者中断，因为他们将收到他们不理解的格式的消息。</td><td>string</td><td>1.0-IV0</td><td></td><td>log.message.format.version</td><td>medium</td></tr>
<tr>
<td>message.timestamp.difference.max.ms</td><td>broker接收消息时所允许的时间戳与消息中指定的时间戳之间的最大差异。如果message.timestamp.type=CreateTime，则如果时间戳的差异超过此阈值，则将拒绝消息。如果message.timestamp.type=LogAppendTime，则忽略此配置。</td><td>long</td><td>9223372036854775807</td><td>[0,...]</td><td>log.message.timestamp.difference.max.ms</td><td>medium</td></tr>
<tr>
<td>message.timestamp.type</td><td>定义消息中的时间戳是消息创建时间还是日志附加时间。值应该是“CreateTime”或“LogAppendTime”</td><td>string</td><td>CreateTime</td><td></td><td>log.message.timestamp.type</td><td>medium</td></tr>
<tr>
<td>min.cleanable.dirty.ratio</td><td>此配置控制日志压缩程序尝试清理日志的频率(假设启用了<a href="#compaction">日志压缩</a> )。默认情况下，我们将避免清除超过50%的日志已经压缩的日志。这个比率限制了重复在日志中浪费的最大空间(最多为50%，日志中最多有50%可能是重复的)。一个更高的比率将意味着更少，更有效的清理，但将意味着在日志中浪费更多的空间。</td><td>double</td><td>0.5</td><td>[0,...,1]</td><td>log.cleaner.min.cleanable.ratio</td><td>medium</td></tr>
<tr>
<td>min.compaction.lag.ms</td><td>消息在日志中保持未压缩的最短时间。仅适用于正在压缩的日志。</td><td>long</td><td>0</td><td>[0,...]</td><td>log.cleaner.min.compaction.lag.ms</td><td>medium</td></tr>
<tr>
<td>min.insync.replicas</td><td>当producer将ack设置为“all”(或“-1”)时，此配置指定必须确认写入才能被认为成功的副本的最小数量。如果这个最小值无法满足，那么producer将引发一个异常(NotEnough Replicas或NotEnough ReplicasAfterAppend)。<br>当使用时，min.insync.Copicas和ack允许您执行更好的持久性保证。一个典型的场景是创建一个复制因子为3的topic，将min.insync.Copicas设置为2，并生成带有“All”的ack。这将确保如果大多数副本没有接收到写，则producer将引发异常。</td><td>int</td><td>1</td><td>[1,...]</td><td>min.insync.replicas</td><td>medium</td></tr>
<tr>
<td>preallocate</td><td>如果在创建新的日志段时应该预先分配磁盘上的文件，则为True。</td><td>boolean</td><td>false</td><td></td><td>log.preallocate</td><td>medium</td></tr>
<tr>
<td>retention.bytes</td><td>如果使用“delete”保留策略，此配置控制分区(由日志段组成)在放弃旧日志段以释放空间之前的最大大小。默认情况下，没有大小限制，只有时间限制。由于此限制是在分区级别强制执行的，因此，将其乘以分区数，计算出topic保留值，以字节为单位。</td><td>long</td><td>-1</td><td></td><td>log.retention.bytes</td><td>medium</td></tr>
<tr>
<td>retention.ms</td><td>如果使用“delete”保留策略，此配置控制保留日志的最长时间，然后将旧日志段丢弃以释放空间。这代表了用户读取数据的速度的SLA。</td><td>long</td><td>604800000</td><td></td><td>log.retention.ms</td><td>medium</td></tr>
<tr>
<td>segment.bytes</td><td>此配置控制日志的段文件大小。保留和清理总是一次完成一个文件，所以更大的段大小意味着更少的文件，但对保留的粒度控制更少。</td><td>int</td><td>1073741824</td><td>[14,...]</td><td>log.segment.bytes</td><td>medium</td></tr>
<tr>
<td>segment.index.bytes</td><td>此配置控制将偏移量映射到文件位置的索引大小。我们预先分配这个索引文件并且只在日志滚动后收缩它。您通常不需要更改此设置。</td><td>int</td><td>10485760</td><td>[0,...]</td><td>log.index.size.max.bytes</td><td>medium</td></tr>
<tr>
<td>segment.jitter.ms</td><td>从预定的分段滚动时间减去最大随机抖动，以避免段滚动产生惊群效应。</td><td>long</td><td>0</td><td>[0,...]</td><td>log.roll.jitter.ms</td><td>medium</td></tr>
<tr>
<td>segment.ms</td><td>这个配置控制在一段时间后，Kafka将强制日志滚动，即使段文件没有满，以确保保留空间可以删除或压缩旧数据。</td><td>long</td><td>604800000</td><td>[0,...]</td><td>log.roll.ms</td><td>medium</td></tr>
<tr>
<td>unclean.leader.election.enable</td><td>指示是否启用ISR中没有的副本作为当选为领导者的最后手段，即使这样做可能导致数据丢失。</td><td>boolean</td><td>false</td><td></td><td>unclean.leader.election.enable</td><td>medium</td></tr>
</tbody></table>
