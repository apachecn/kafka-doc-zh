<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_80) on Thu Feb 11 18:46:38 CST 2016 -->
<title>KafkaConsumer (clients 0.9.0.1 API)</title>
<meta name="date" content="2016-02-11">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="KafkaConsumer (clients 0.9.0.1 API)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/kafka/clients/consumer/InvalidOffsetException.html" title="class in org.apache.kafka.clients.consumer"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/kafka/clients/consumer/MockConsumer.html" title="class in org.apache.kafka.clients.consumer"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html" target="_top">Frames</a></li>
<li><a href="KafkaConsumer.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.kafka.clients.consumer</div>
<h2 title="Class KafkaConsumer" class="title">Class KafkaConsumer&lt;K,V&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.apache.kafka.clients.consumer.KafkaConsumer&lt;K,V&gt;</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Closeable, java.lang.AutoCloseable, <a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;K,V&gt;</dd>
</dl>
<hr>
<br>
<pre>@InterfaceStability.Unstable
public class <span class="strong">KafkaConsumer&lt;K,V&gt;</span>
extends java.lang.Object
implements <a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;K,V&gt;</pre>
<div class="block">A Kafka client that consumes records from a Kafka cluster.
 <p>
 It will transparently handle the failure of servers in the Kafka cluster, and transparently adapt as partitions of
 data it fetches migrate within the cluster. This client also interacts with the server to allow groups of
 consumers to load balance consumption using consumer groups (as described below).
 <p>
 The consumer maintains TCP connections to the necessary brokers to fetch data.
 Failure to close the consumer after use will leak these connections.
 The consumer is not thread-safe. See <a href="#multithreaded">Multi-threaded Processing</a> for more details.

 <h3>Offsets and Consumer Position</h3>
 Kafka maintains a numerical offset for each record in a partition. This offset acts as a kind of unique identifier of
 a record within that partition, and also denotes the position of the consumer in the partition. That is, a consumer
 which has position 5 has consumed records with offsets 0 through 4 and will next receive record with offset 5. There
 are actually two notions of position relevant to the user of the consumer.
 <p>
 The <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#position(org.apache.kafka.common.TopicPartition)"><code>position</code></a> of the consumer gives the offset of the next record that will be given
 out. It will be one larger than the highest offset the consumer has seen in that partition. It automatically advances
 every time the consumer receives data calls <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(long)</code></a> and receives messages.
 <p>
 The <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync()"><code>committed position</code></a> is the last offset that has been saved securely. Should the
 process fail and restart, this is the offset that it will recover to. The consumer can either automatically commit
 offsets periodically; or it can choose to control this committed position manually by calling
 <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync()"><code>commitSync</code></a>, which will block until the offsets have been successfully committed
 or fatal error has happened during the commit process, or <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync(org.apache.kafka.clients.consumer.OffsetCommitCallback)"><code>commitAsync</code></a> which is non-blocking
 and will trigger <a href="../../../../../org/apache/kafka/clients/consumer/OffsetCommitCallback.html" title="interface in org.apache.kafka.clients.consumer"><code>OffsetCommitCallback</code></a> upon either successfully committed or fatally failed.
 <p>
 This distinction gives the consumer control over when a record is considered consumed. It is discussed in further
 detail below.

 <h3>Consumer Groups and Topic Subscriptions</h3>

 Kafka uses the concept of <i>consumer groups</i> to allow a pool of processes to divide up the work of consuming and
 processing records. These processes can either be running on the same machine or, as is more likely, they can be
 distributed over many machines to provide additional scalability and fault tolerance for processing.
 <p>
 Each Kafka consumer is able to configure a consumer group that it belongs to, and can dynamically set the
 list of topics it wants to subscribe to through <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(List, ConsumerRebalanceListener)</code></a>,
 or subscribe to all topics matching certain pattern through <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.regex.Pattern,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(Pattern, ConsumerRebalanceListener)</code></a>.
 Kafka will deliver each message in the
 subscribed topics to one process in each consumer group. This is achieved by balancing the partitions in the topic
 over the consumer processes in each group. So if there is a topic with four partitions, and a consumer group with two
 processes, each process would consume from two partitions. This group membership is maintained dynamically: if a
 process fails the partitions assigned to it will be reassigned to other processes in the same group, and if a new
 process joins the group, partitions will be moved from existing consumers to this new process.
 <p>
 So if two processes subscribe to a topic both specifying different groups they will each get all the records in that
 topic; if they both specify the same group they will each get about half the records.
 <p>
 Conceptually you can think of a consumer group as being a single logical subscriber that happens to be made up of
 multiple processes. As a multi-subscriber system, Kafka naturally supports having any number of consumer groups for a
 given topic without duplicating data (additional consumers are actually quite cheap).
 <p>
 This is a slight generalization of the functionality that is common in messaging systems. To get semantics similar to
 a queue in a traditional messaging system all processes would be part of a single consumer group and hence record
 delivery would be balanced over the group like with a queue. Unlike a traditional messaging system, though, you can
 have multiple such groups. To get semantics similar to pub-sub in a traditional messaging system each process would
 have its own consumer group, so each process would subscribe to all the records published to the topic.
 <p>
 In addition, when group reassignment happens automatically, consumers can be notified through <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a>,
 which allows them to finish necessary application-level logic such as state cleanup, manual offset
 commits (note that offsets are always committed for a given consumer group), etc.
 See <a href="#rebalancecallback">Storing Offsets Outside Kafka</a> for more details
 <p>
 It is also possible for the consumer to manually specify the partitions that are assigned to it through <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)"><code>assign(List)</code></a>,
 which disables this dynamic partition assignment.

 <h3>Usage Examples</h3>
 The consumer APIs offer flexibility to cover a variety of consumption use cases. Here are some examples to
 demonstrate how to use them.

 <h4>Automatic Offset Committing</h4>
 This example demonstrates a simple usage of Kafka's consumer api that relying on automatic offset committing.
 <p>
 <pre>
     Properties props = new Properties();
     props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
     props.put(&quot;group.id&quot;, &quot;test&quot;);
     props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
     props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);
     props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;);
     props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
     props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
     KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
     consumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));
     while (true) {
         ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
         for (ConsumerRecord&lt;String, String&gt; record : records)
             System.out.printf(&quot;offset = %d, key = %s, value = %s&quot;, record.offset(), record.key(), record.value());
     }
 </pre>

 Setting <code>enable.auto.commit</code> means that offsets are committed automatically with a frequency controlled by
 the config <code>auto.commit.interval.ms</code>.
 <p>
 The connection to the cluster is bootstrapped by specifying a list of one or more brokers to contact using the
 configuration <code>bootstrap.servers</code>. This list is just used to discover the rest of the brokers in the
 cluster and need not be an exhaustive list of servers in the cluster (though you may want to specify more than one in
 case there are servers down when the client is connecting).
 <p>
 In this example the client is subscribing to the topics <i>foo</i> and <i>bar</i> as part of a group of consumers
 called <i>test</i> as described above.
 <p>
 The broker will automatically detect failed processes in the <i>test</i> group by using a heartbeat mechanism. The
 consumer will automatically ping the cluster periodically, which lets the cluster know that it is alive. As long as
 the consumer is able to do this it is considered alive and retains the right to consume from the partitions assigned
 to it. If it stops heartbeating for a period of time longer than <code>session.timeout.ms</code> then it will be
 considered dead and its partitions will be assigned to another process.
 <p>
 The deserializer settings specify how to turn bytes into objects. For example, by specifying string deserializers, we
 are saying that our record's key and value will just be simple strings.

 <h4>Manual Offset Control</h4>

 Instead of relying on the consumer to periodically commit consumed offsets, users can also control when messages
 should be considered as consumed and hence commit their offsets. This is useful when the consumption of the messages
 are coupled with some processing logic and hence a message should not be considered as consumed until it is completed processing.
 In this example we will consume a batch of records and batch them up in memory, when we have sufficient records
 batched we will insert them into a database. If we allowed offsets to auto commit as in the previous example messages
 would be considered consumed after they were given out by the consumer, and it would be possible that our process
 could fail after we have read messages into our in-memory buffer but before they had been inserted into the database.
 To avoid this we will manually commit the offsets only once the corresponding messages have been inserted into the
 database. This gives us exact control of when a message is considered consumed. This raises the opposite possibility:
 the process could fail in the interval after the insert into the database but before the commit (even though this
 would likely just be a few milliseconds, it is a possibility). In this case the process that took over consumption
 would consume from last committed offset and would repeat the insert of the last batch of data. Used in this way
 Kafka provides what is often called "at-least once delivery" guarantees, as each message will likely be delivered one
 time but in failure cases could be duplicated.
 <p>
 <pre>
     Properties props = new Properties();
     props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
     props.put(&quot;group.id&quot;, &quot;test&quot;);
     props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);
     props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);
     props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;);
     props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
     props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
     KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
     consumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));
     final int minBatchSize = 200;
     List&lt;ConsumerRecord&lt;String, String&gt;&gt; buffer = new ArrayList&lt;&gt;();
     while (true) {
         ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
         for (ConsumerRecord&lt;String, String&gt; record : records) {
             buffer.add(record);
         }
         if (buffer.size() &gt;= minBatchSize) {
             insertIntoDb(buffer);
             consumer.commitSync();
             buffer.clear();
         }
     }
 </pre>

 The above example uses <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync()"><code>commitSync</code></a> to mark all received messages as committed. In some cases
 you may wish to have even finer control over which messages have been committed by specifying an offset explicitly.
 In the example below we commit offset after we finish handling the messages in each partition.
 <p>
 <pre>
     try {
         while(running) {
             ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE);
             for (TopicPartition partition : records.partitions()) {
                 List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords = records.records(partition);
                 for (ConsumerRecord&lt;String, String&gt; record : partitionRecords) {
                     System.out.println(record.offset() + &quot;: &quot; + record.value());
                 }
                 long lastOffset = partitionRecords.get(partitionRecords.size() - 1).offset();
                 consumer.commitSync(Collections.singletonMap(partition, new OffsetAndMetadata(lastOffset + 1)));
             }
         }
     } finally {
       consumer.close();
     }
 </pre>

 <b>Note: The committed offset should always be the offset of the next message that your application will read.</b>
 Thus, when calling <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync(java.util.Map)"><code>commitSync(offsets)</code></a> you should add one to the offset of the last message processed.

 <h4>Subscribing To Specific Partitions</h4>

 In the previous examples we subscribed to the topics we were interested in and let Kafka give our particular process
 a fair share of the partitions for those topics. This provides a simple load balancing mechanism so multiple
 instances of our program can divided up the work of processing records.
 <p>
 In this mode the consumer will just get the partitions it subscribes to and if the consumer instance fails no attempt
 will be made to rebalance partitions to other instances.
 <p>
 There are several cases where this makes sense:
 <ul>
 <li>The first case is if the process is maintaining some kind of local state associated with that partition (like a
 local on-disk key-value store) and hence it should only get records for the partition it is maintaining on disk.
 <li>Another case is if the process itself is highly available and will be restarted if it fails (perhaps using a
 cluster management framework like YARN, Mesos, or AWS facilities, or as part of a stream processing framework). In
 this case there is no need for Kafka to detect the failure and reassign the partition, rather the consuming process
 will be restarted on another machine.
 </ul>
 <p>
 This mode is easy to specify, rather than subscribing to the topic, the consumer just subscribes to particular
 partitions:

 <pre>
     String topic = &quot;foo&quot;;
     TopicPartition partition0 = new TopicPartition(topic, 0);
     TopicPartition partition1 = new TopicPartition(topic, 1);
     consumer.assign(Arrays.asList(partition0, partition1));
 </pre>

 The group that the consumer specifies is still used for committing offsets, but now the set of partitions will only
 be changed if the consumer specifies new partitions, and no attempt at failure detection will be made.
 <p>
 It isn't possible to mix both subscription to specific partitions (with no load balancing) and to topics (with load
 balancing) using the same consumer instance.

 <h4><a name="rebalancecallback">Storing Offsets Outside Kafka</h4>

 The consumer application need not use Kafka's built-in offset storage, it can store offsets in a store of its own
 choosing. The primary use case for this is allowing the application to store both the offset and the results of the
 consumption in the same system in a way that both the results and offsets are stored atomically. This is not always
 possible, but when it is it will make the consumption fully atomic and give "exactly once" semantics that are
 stronger than the default "at-least once" semantics you get with Kafka's offset commit functionality.
 <p>
 Here are a couple of examples of this type of usage:
 <ul>
 <li>If the results of the consumption are being stored in a relational database, storing the offset in the database
 as well can allow committing both the results and offset in a single transaction. Thus either the transaction will
 succeed and the offset will be updated based on what was consumed or the result will not be stored and the offset
 won't be updated.
 <li>If the results are being stored in a local store it may be possible to store the offset there as well. For
 example a search index could be built by subscribing to a particular partition and storing both the offset and the
 indexed data together. If this is done in a way that is atomic, it is often possible to have it be the case that even
 if a crash occurs that causes unsync'd data to be lost, whatever is left has the corresponding offset stored as well.
 This means that in this case the indexing process that comes back having lost recent updates just resumes indexing
 from what it has ensuring that no updates are lost.
 </ul>
 <p>
 Each record comes with its own offset, so to manage your own offset you just need to do the following:

 <ul>
 <li>Configure <code>enable.auto.commit=false</code>
 <li>Use the offset provided with each <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRecord.html" title="class in org.apache.kafka.clients.consumer"><code>ConsumerRecord</code></a> to save your position.
 <li>On restart restore the position of the consumer using <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seek(org.apache.kafka.common.TopicPartition,%20long)"><code>seek(TopicPartition, long)</code></a>.
 </ul>

 <p>
 This type of usage is simplest when the partition assignment is also done manually (this would be likely in the
 search index use case described above). If the partition assignment is done automatically special care is
 needed to handle the case where partition assignments change. This can be done by providing a
 <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a> instance in the call to <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(List, ConsumerRebalanceListener)</code></a>
 and <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.regex.Pattern,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(Pattern, ConsumerRebalanceListener)</code></a>.
 For example, when partitions are taken from a consumer the consumer will want to commit its offset for those partitions by
 implementing <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsRevoked(java.util.Collection)"><code>ConsumerRebalanceListener.onPartitionsRevoked(Collection)</code></a>. When partitions are assigned to a
 consumer, the consumer will want to look up the offset for those new partitions and correctly initialize the consumer
 to that position by implementing <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsAssigned(java.util.Collection)"><code>ConsumerRebalanceListener.onPartitionsAssigned(Collection)</code></a>.
 <p>
 Another common use for <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a> is to flush any caches the application maintains for
 partitions that are moved elsewhere.

 <h4>Controlling The Consumer's Position</h4>

 In most use cases the consumer will simply consume records from beginning to end, periodically committing its
 position (either automatically or manually). However Kafka allows the consumer to manually control its position,
 moving forward or backwards in a partition at will. This means a consumer can re-consume older records, or skip to
 the most recent records without actually consuming the intermediate records.
 <p>
 There are several instances where manually controlling the consumer's position can be useful.
 <p>
 One case is for time-sensitive record processing it may make sense for a consumer that falls far enough behind to not
 attempt to catch up processing all records, but rather just skip to the most recent records.
 <p>
 Another use case is for a system that maintains local state as described in the previous section. In such a system
 the consumer will want to initialize its position on start-up to whatever is contained in the local store. Likewise
 if the local state is destroyed (say because the disk is lost) the state may be recreated on a new machine by
 re-consuming all the data and recreating the state (assuming that Kafka is retaining sufficient history).
 <p>
 Kafka allows specifying the position using <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seek(org.apache.kafka.common.TopicPartition,%20long)"><code>seek(TopicPartition, long)</code></a> to specify the new position. Special
 methods for seeking to the earliest and latest offset the server maintains are also available (
 <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seekToBeginning(org.apache.kafka.common.TopicPartition...)"><code>seekToBeginning(TopicPartition...)</code></a> and <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seekToEnd(org.apache.kafka.common.TopicPartition...)"><code>seekToEnd(TopicPartition...)</code></a> respectively).

 <h4>Consumption Flow Control</h4>

 If a consumer is assigned multiple partitions to fetch data from, it will try to consume from all of them at the same time,
 effectively giving these partitions the same priority for consumption. However in some cases consumers may want to
 first focus on fetching from some subset of the assigned partitions at full speed, and only start fetching other partitions
 when these partitions have few or no data to consume.

 <p>
 One of such cases is stream processing, where processor fetches from two topics and performs the join on these two streams.
 When one of the topic is long lagging behind the other, the processor would like to pause fetching from the ahead topic
 in order to get the lagging stream to catch up. Another example is bootstraping upon consumer starting up where there are
 a lot of history data to catch up, the applciations usually wants to get the latest data on some of the topics before consider
 fetching other topics.

 <p>
 Kafka supports dynamic controlling of consumption flows by using <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#pause(org.apache.kafka.common.TopicPartition...)"><code>pause(TopicPartition...)</code></a> and <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#resume(org.apache.kafka.common.TopicPartition...)"><code>resume(TopicPartition...)</code></a>
 to pause the consumption on the specified assigned partitions and resume the consumption
 on the specified paused partitions respectively in the future <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(long)</code></a> calls.

 <h3><a name="multithreaded">Multi-threaded Processing</a></h3>

 The Kafka consumer is NOT thread-safe. All network I/O happens in the thread of the application
 making the call. It is the responsibility of the user to ensure that multi-threaded access
 is properly synchronized. Un-synchronized access will result in <code>ConcurrentModificationException</code>.

 <p>
 The only exception to this rule is <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a>, which can safely be used from an external thread to
 interrupt an active operation. In this case, a <a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors"><code>WakeupException</code></a> will be
 thrown from the thread blocking on the operation. This can be used to shutdown the consumer from another thread.
 The following snippet shows the typical pattern:

 <pre>
 public class KafkaConsumerRunner implements Runnable {
     private final AtomicBoolean closed = new AtomicBoolean(false);
     private final KafkaConsumer consumer;

     public void run() {
         try {
             consumer.subscribe(Arrays.asList("topic"));
             while (!closed.get()) {
                 ConsumerRecords records = consumer.poll(10000);
                 // Handle new records
             }
         } catch (WakeupException e) {
             // Ignore exception if closing
             if (!closed.get()) throw e;
         } finally {
             consumer.close();
         }
     }

     // Shutdown hook which can be called from a separate thread
     public void shutdown() {
         closed.set(true);
         consumer.wakeup();
     }
 }
 </pre>

 Then in a separate thread, the consumer can be shutdown by setting the closed flag and waking up the consumer.

 <p>
 <pre>
     closed.set(true);
     consumer.wakeup();
 </pre>

 <p>
 We have intentionally avoided implementing a particular threading model for processing. This leaves several
 options for implementing multi-threaded processing of records.


 <h4>1. One Consumer Per Thread</h4>

 A simple option is to give each thread its own consumer instance. Here are the pros and cons of this approach:
 <ul>
 <li><b>PRO</b>: It is the easiest to implement
 <li><b>PRO</b>: It is often the fastest as no inter-thread co-ordination is needed
 <li><b>PRO</b>: It makes in-order processing on a per-partition basis very easy to implement (each thread just
 processes messages in the order it receives them).
 <li><b>CON</b>: More consumers means more TCP connections to the cluster (one per thread). In general Kafka handles
 connections very efficiently so this is generally a small cost.
 <li><b>CON</b>: Multiple consumers means more requests being sent to the server and slightly less batching of data
 which can cause some drop in I/O throughput.
 <li><b>CON</b>: The number of total threads across all processes will be limited by the total number of partitions.
 </ul>

 <h4>2. Decouple Consumption and Processing</h4>

 Another alternative is to have one or more consumer threads that do all data consumption and hands off
 <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRecords.html" title="class in org.apache.kafka.clients.consumer"><code>ConsumerRecords</code></a> instances to a blocking queue consumed by a pool of processor threads that actually handle
 the record processing.

 This option likewise has pros and cons:
 <ul>
 <li><b>PRO</b>: This option allows independently scaling the number of consumers and processors. This makes it
 possible to have a single consumer that feeds many processor threads, avoiding any limitation on partitions.
 <li><b>CON</b>: Guaranteeing order across the processors requires particular care as the threads will execute
 independently an earlier chunk of data may actually be processed after a later chunk of data just due to the luck of
 thread execution timing. For processing that has no ordering requirements this is not a problem.
 <li><b>CON</b>: Manually committing the position becomes harder as it requires that all threads co-ordinate to ensure
 that processing is complete for that partition.
 </ul>

 There are many possible variations on this approach. For example each processor thread can have its own queue, and
 the consumer threads can hash into these queues using the TopicPartition to ensure in-order consumption and simplify
 commit.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#KafkaConsumer(java.util.Map)">KafkaConsumer</a></strong>(java.util.Map&lt;java.lang.String,java.lang.Object&gt;&nbsp;configs)</code>
<div class="block">A consumer is instantiated by providing a set of key-value pairs as configuration.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#KafkaConsumer(java.util.Map,%20org.apache.kafka.common.serialization.Deserializer,%20org.apache.kafka.common.serialization.Deserializer)">KafkaConsumer</a></strong>(java.util.Map&lt;java.lang.String,java.lang.Object&gt;&nbsp;configs,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>&gt;&nbsp;keyDeserializer,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;&nbsp;valueDeserializer)</code>
<div class="block">A consumer is instantiated by providing a set of key-value pairs as configuration, a
 <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a> implementation, a key and a value <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#KafkaConsumer(java.util.Properties)">KafkaConsumer</a></strong>(java.util.Properties&nbsp;properties)</code>
<div class="block">A consumer is instantiated by providing a <code>Properties</code> object as configuration.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#KafkaConsumer(java.util.Properties,%20org.apache.kafka.common.serialization.Deserializer,%20org.apache.kafka.common.serialization.Deserializer)">KafkaConsumer</a></strong>(java.util.Properties&nbsp;properties,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>&gt;&nbsp;keyDeserializer,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;&nbsp;valueDeserializer)</code>
<div class="block">A consumer is instantiated by providing a <code>Properties</code> object as configuration and a
 <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a> implementation, a key and a value <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)">assign</a></strong>(java.util.List&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&gt;&nbsp;partitions)</code>
<div class="block">Manually assign a list of partition to this consumer.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.Set&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assignment()">assignment</a></strong>()</code>
<div class="block">Get the set of partitions currently assigned to this consumer.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#close()">close</a></strong>()</code>
<div class="block">Close the consumer, waiting indefinitely for any needed cleanup.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync()">commitAsync</a></strong>()</code>
<div class="block">Commit offsets returned on the last <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll()</code></a> for all the subscribed list of topics and partition.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync(java.util.Map,%20org.apache.kafka.clients.consumer.OffsetCommitCallback)">commitAsync</a></strong>(java.util.Map&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>,<a href="../../../../../org/apache/kafka/clients/consumer/OffsetAndMetadata.html" title="class in org.apache.kafka.clients.consumer">OffsetAndMetadata</a>&gt;&nbsp;offsets,
           <a href="../../../../../org/apache/kafka/clients/consumer/OffsetCommitCallback.html" title="interface in org.apache.kafka.clients.consumer">OffsetCommitCallback</a>&nbsp;callback)</code>
<div class="block">Commit the specified offsets for the specified list of topics and partitions to Kafka.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync(org.apache.kafka.clients.consumer.OffsetCommitCallback)">commitAsync</a></strong>(<a href="../../../../../org/apache/kafka/clients/consumer/OffsetCommitCallback.html" title="interface in org.apache.kafka.clients.consumer">OffsetCommitCallback</a>&nbsp;callback)</code>
<div class="block">Commit offsets returned on the last <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll()</code></a> for the subscribed list of topics and partitions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync()">commitSync</a></strong>()</code>
<div class="block">Commit offsets returned on the last <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll()</code></a> for all the subscribed list of topics and partitions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync(java.util.Map)">commitSync</a></strong>(java.util.Map&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>,<a href="../../../../../org/apache/kafka/clients/consumer/OffsetAndMetadata.html" title="class in org.apache.kafka.clients.consumer">OffsetAndMetadata</a>&gt;&nbsp;offsets)</code>
<div class="block">Commit the specified offsets for the specified list of topics and partitions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/kafka/clients/consumer/OffsetAndMetadata.html" title="class in org.apache.kafka.clients.consumer">OffsetAndMetadata</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#committed(org.apache.kafka.common.TopicPartition)">committed</a></strong>(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&nbsp;partition)</code>
<div class="block">Get the last committed offset for the given partition (whether the commit happened by this process or
 another).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,java.util.List&lt;<a href="../../../../../org/apache/kafka/common/PartitionInfo.html" title="class in org.apache.kafka.common">PartitionInfo</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#listTopics()">listTopics</a></strong>()</code>
<div class="block">Get metadata about partitions for all topics that the user is authorized to view.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Map&lt;<a href="../../../../../org/apache/kafka/common/MetricName.html" title="class in org.apache.kafka.common">MetricName</a>,? extends <a href="../../../../../org/apache/kafka/common/Metric.html" title="interface in org.apache.kafka.common">Metric</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#metrics()">metrics</a></strong>()</code>
<div class="block">Get the metrics kept by the consumer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../../org/apache/kafka/common/PartitionInfo.html" title="class in org.apache.kafka.common">PartitionInfo</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#partitionsFor(java.lang.String)">partitionsFor</a></strong>(java.lang.String&nbsp;topic)</code>
<div class="block">Get metadata about the partitions for a given topic.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#pause(org.apache.kafka.common.TopicPartition...)">pause</a></strong>(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</code>
<div class="block">Suspend fetching from the requested partitions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRecords.html" title="class in org.apache.kafka.clients.consumer">ConsumerRecords</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)">poll</a></strong>(long&nbsp;timeout)</code>
<div class="block">Fetch data for the topics or partitions specified using one of the subscribe/assign APIs.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#position(org.apache.kafka.common.TopicPartition)">position</a></strong>(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&nbsp;partition)</code>
<div class="block">Get the offset of the <i>next record</i> that will be fetched (if a record with that offset exists).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#resume(org.apache.kafka.common.TopicPartition...)">resume</a></strong>(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</code>
<div class="block">Resume specified partitions which have been paused with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#pause(org.apache.kafka.common.TopicPartition...)"><code>pause(TopicPartition...)</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seek(org.apache.kafka.common.TopicPartition,%20long)">seek</a></strong>(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&nbsp;partition,
    long&nbsp;offset)</code>
<div class="block">Overrides the fetch offsets that the consumer will use on the next <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(timeout)</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seekToBeginning(org.apache.kafka.common.TopicPartition...)">seekToBeginning</a></strong>(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</code>
<div class="block">Seek to the first offset for each of the given partitions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seekToEnd(org.apache.kafka.common.TopicPartition...)">seekToEnd</a></strong>(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</code>
<div class="block">Seek to the last offset for each of the given partitions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List)">subscribe</a></strong>(java.util.List&lt;java.lang.String&gt;&nbsp;topics)</code>
<div class="block">Subscribe to the given list of topics to get dynamically assigned partitions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)">subscribe</a></strong>(java.util.List&lt;java.lang.String&gt;&nbsp;topics,
         <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer">ConsumerRebalanceListener</a>&nbsp;listener)</code>
<div class="block">Subscribe to the given list of topics to get dynamically
 assigned partitions.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.regex.Pattern,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)">subscribe</a></strong>(java.util.regex.Pattern&nbsp;pattern,
         <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer">ConsumerRebalanceListener</a>&nbsp;listener)</code>
<div class="block">Subscribe to all topics matching specified pattern to get dynamically assigned partitions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Set&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscription()">subscription</a></strong>()</code>
<div class="block">Get the current subscription.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#unsubscribe()">unsubscribe</a></strong>()</code>
<div class="block">Unsubscribe from topics currently subscribed with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List)"><code>subscribe(List)</code></a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()">wakeup</a></strong>()</code>
<div class="block">Wakeup the consumer.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="KafkaConsumer(java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>KafkaConsumer</h4>
<pre>public&nbsp;KafkaConsumer(java.util.Map&lt;java.lang.String,java.lang.Object&gt;&nbsp;configs)</pre>
<div class="block">A consumer is instantiated by providing a set of key-value pairs as configuration. Valid configuration strings
 are documented <a href="http://kafka.apache.org/documentation.html#consumerconfigs" >here</a>. Values can be
 either strings or objects of the appropriate type (for example a numeric configuration would accept either the
 string "42" or the integer 42).
 <p>
 Valid configuration strings are documented at <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerConfig.html" title="class in org.apache.kafka.clients.consumer"><code>ConsumerConfig</code></a></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>configs</code> - The consumer configs</dd></dl>
</li>
</ul>
<a name="KafkaConsumer(java.util.Map, org.apache.kafka.common.serialization.Deserializer, org.apache.kafka.common.serialization.Deserializer)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>KafkaConsumer</h4>
<pre>public&nbsp;KafkaConsumer(java.util.Map&lt;java.lang.String,java.lang.Object&gt;&nbsp;configs,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>&gt;&nbsp;keyDeserializer,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;&nbsp;valueDeserializer)</pre>
<div class="block">A consumer is instantiated by providing a set of key-value pairs as configuration, a
 <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a> implementation, a key and a value <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>.
 <p>
 Valid configuration strings are documented at <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerConfig.html" title="class in org.apache.kafka.clients.consumer"><code>ConsumerConfig</code></a></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>configs</code> - The consumer configs</dd><dd><code>keyDeserializer</code> - The deserializer for key that implements <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>. The configure() method
            won't be called in the consumer when the deserializer is passed in directly.</dd><dd><code>valueDeserializer</code> - The deserializer for value that implements <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>. The configure() method
            won't be called in the consumer when the deserializer is passed in directly.</dd></dl>
</li>
</ul>
<a name="KafkaConsumer(java.util.Properties)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>KafkaConsumer</h4>
<pre>public&nbsp;KafkaConsumer(java.util.Properties&nbsp;properties)</pre>
<div class="block">A consumer is instantiated by providing a <code>Properties</code> object as configuration. Valid
 configuration strings are documented at <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerConfig.html" title="class in org.apache.kafka.clients.consumer"><code>ConsumerConfig</code></a> A consumer is instantiated by providing a
 <code>Properties</code> object as configuration. Valid configuration strings are documented at
 <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerConfig.html" title="class in org.apache.kafka.clients.consumer"><code>ConsumerConfig</code></a></div>
</li>
</ul>
<a name="KafkaConsumer(java.util.Properties, org.apache.kafka.common.serialization.Deserializer, org.apache.kafka.common.serialization.Deserializer)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>KafkaConsumer</h4>
<pre>public&nbsp;KafkaConsumer(java.util.Properties&nbsp;properties,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>&gt;&nbsp;keyDeserializer,
             <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization">Deserializer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;&nbsp;valueDeserializer)</pre>
<div class="block">A consumer is instantiated by providing a <code>Properties</code> object as configuration and a
 <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a> implementation, a key and a value <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>.
 <p>
 Valid configuration strings are documented at <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerConfig.html" title="class in org.apache.kafka.clients.consumer"><code>ConsumerConfig</code></a></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>properties</code> - The consumer configuration properties</dd><dd><code>keyDeserializer</code> - The deserializer for key that implements <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>. The configure() method
            won't be called in the consumer when the deserializer is passed in directly.</dd><dd><code>valueDeserializer</code> - The deserializer for value that implements <a href="../../../../../org/apache/kafka/common/serialization/Deserializer.html" title="interface in org.apache.kafka.common.serialization"><code>Deserializer</code></a>. The configure() method
            won't be called in the consumer when the deserializer is passed in directly.</dd></dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="assignment()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>assignment</h4>
<pre>public&nbsp;java.util.Set&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&gt;&nbsp;assignment()</pre>
<div class="block">Get the set of partitions currently assigned to this consumer. If subscription happened by directly assigning
 partitions using <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)"><code>assign(List)</code></a> then this will simply return the same partitions that
 were assigned. If topic subscription was used, then this will give the set of topic partitions currently assigned
 to the consumer (which may be none if the assignment hasn't happened yet, or the partitions are in the
 process of getting reassigned).</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#assignment()">assignment</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Returns:</span></dt><dd>The set of partitions currently assigned to this consumer</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assignment()"><code>assignment()</code></a></dd></dl>
</li>
</ul>
<a name="subscription()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subscription</h4>
<pre>public&nbsp;java.util.Set&lt;java.lang.String&gt;&nbsp;subscription()</pre>
<div class="block">Get the current subscription. Will return the same topics used in the most recent call to
 <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(List, ConsumerRebalanceListener)</code></a>, or an empty set if no such call has been made.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#subscription()">subscription</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Returns:</span></dt><dd>The set of topics currently subscribed to</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscription()"><code>subscription()</code></a></dd></dl>
</li>
</ul>
<a name="subscribe(java.util.List, org.apache.kafka.clients.consumer.ConsumerRebalanceListener)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subscribe</h4>
<pre>public&nbsp;void&nbsp;subscribe(java.util.List&lt;java.lang.String&gt;&nbsp;topics,
             <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer">ConsumerRebalanceListener</a>&nbsp;listener)</pre>
<div class="block">Subscribe to the given list of topics to get dynamically
 assigned partitions. <b>Topic subscriptions are not incremental. This list will replace the current
 assignment (if there is one).</b> Note that it is not possible to combine topic subscription with group management
 with manual partition assignment through <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)"><code>assign(List)</code></a>.

 If the given list of topics is empty, it is treated the same as <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#unsubscribe()"><code>unsubscribe()</code></a>.

 <p>
 As part of group management, the consumer will keep track of the list of consumers that belong to a particular
 group and will trigger a rebalance operation if one of the following events trigger -
 <ul>
 <li>Number of partitions change for any of the subscribed list of topics
 <li>Topic is created or deleted
 <li>An existing member of the consumer group dies
 <li>A new member is added to an existing consumer group via the join API
 </ul>
 <p>
 When any of these events are triggered, the provided listener will be invoked first to indicate that
 the consumer's assignment has been revoked, and then again when the new assignment has been received.
 Note that this listener will immediately override any listener set in a previous call to subscribe.
 It is guaranteed, however, that the partitions revoked/assigned through this interface are from topics
 subscribed in this call. See <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer"><code>ConsumerRebalanceListener</code></a> for more details.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)">subscribe</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>topics</code> - The list of topics to subscribe to</dd><dd><code>listener</code> - Non-null listener instance to get notifications on partition assignment/revocation for the
                 subscribed topics</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(List, ConsumerRebalanceListener)</code></a></dd></dl>
</li>
</ul>
<a name="subscribe(java.util.List)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subscribe</h4>
<pre>public&nbsp;void&nbsp;subscribe(java.util.List&lt;java.lang.String&gt;&nbsp;topics)</pre>
<div class="block">Subscribe to the given list of topics to get dynamically assigned partitions.
 <b>Topic subscriptions are not incremental. This list will replace the current
 assignment (if there is one).</b> It is not possible to combine topic subscription with group management
 with manual partition assignment through <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)"><code>assign(List)</code></a>.

 If the given list of topics is empty, it is treated the same as <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#unsubscribe()"><code>unsubscribe()</code></a>.

 <p>
 This is a short-hand for <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(List, ConsumerRebalanceListener)</code></a>, which
 uses a noop listener. If you need the ability to either seek to particular offsets, you should prefer
 <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(List, ConsumerRebalanceListener)</code></a>, since group rebalances will cause partition offsets
 to be reset. You should also prefer to provide your own listener if you are doing your own offset
 management since the listener gives you an opportunity to commit offsets before a rebalance finishes.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#subscribe(java.util.List)">subscribe</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>topics</code> - The list of topics to subscribe to</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List)"><code>subscribe(List)</code></a></dd></dl>
</li>
</ul>
<a name="subscribe(java.util.regex.Pattern, org.apache.kafka.clients.consumer.ConsumerRebalanceListener)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subscribe</h4>
<pre>public&nbsp;void&nbsp;subscribe(java.util.regex.Pattern&nbsp;pattern,
             <a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" title="interface in org.apache.kafka.clients.consumer">ConsumerRebalanceListener</a>&nbsp;listener)</pre>
<div class="block">Subscribe to all topics matching specified pattern to get dynamically assigned partitions. The pattern matching will be done periodically against topics
 existing at the time of check.
 <p>
 As part of group management, the consumer will keep track of the list of consumers that
 belong to a particular group and will trigger a rebalance operation if one of the
 following events trigger -
 <ul>
 <li>Number of partitions change for any of the subscribed list of topics
 <li>Topic is created or deleted
 <li>An existing member of the consumer group dies
 <li>A new member is added to an existing consumer group via the join API
 </ul></div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#subscribe(java.util.regex.Pattern,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)">subscribe</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>pattern</code> - Pattern to subscribe to</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.regex.Pattern,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(Pattern, ConsumerRebalanceListener)</code></a></dd></dl>
</li>
</ul>
<a name="unsubscribe()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unsubscribe</h4>
<pre>public&nbsp;void&nbsp;unsubscribe()</pre>
<div class="block">Unsubscribe from topics currently subscribed with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List)"><code>subscribe(List)</code></a>. This
 also clears any partitions directly assigned through <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)"><code>assign(List)</code></a>.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#unsubscribe()">unsubscribe</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#unsubscribe()"><code>unsubscribe()</code></a></dd></dl>
</li>
</ul>
<a name="assign(java.util.List)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>assign</h4>
<pre>public&nbsp;void&nbsp;assign(java.util.List&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&gt;&nbsp;partitions)</pre>
<div class="block">Manually assign a list of partition to this consumer. This interface does not allow for incremental assignment
 and will replace the previous assignment (if there is one).
 <p>
 Manual topic assignment through this method does not use the consumer's group management
 functionality. As such, there will be no rebalance operation triggered when group membership or cluster and topic
 metadata change. Note that it is not possible to use both manual partition assignment with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)"><code>assign(List)</code></a>
 and group assignment with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List,%20org.apache.kafka.clients.consumer.ConsumerRebalanceListener)"><code>subscribe(List, ConsumerRebalanceListener)</code></a>.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#assign(java.util.List)">assign</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>partitions</code> - The list of partitions to assign this consumer</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#assign(java.util.List)"><code>assign(List)</code></a></dd></dl>
</li>
</ul>
<a name="poll(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>poll</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/kafka/clients/consumer/ConsumerRecords.html" title="class in org.apache.kafka.clients.consumer">ConsumerRecords</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;&nbsp;poll(long&nbsp;timeout)</pre>
<div class="block">Fetch data for the topics or partitions specified using one of the subscribe/assign APIs. It is an error to not have
 subscribed to any topics or partitions before polling for data.
 <p>
 On each poll, consumer will try to use the last consumed offset as the starting offset and fetch sequentially. The last
 consumed offset can be manually set through <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seek(org.apache.kafka.common.TopicPartition,%20long)"><code>seek(TopicPartition, long)</code></a> or automatically set as the last committed
 offset for the subscribed list of partitions</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#poll(long)">poll</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>timeout</code> - The time, in milliseconds, spent waiting in poll if data is not available. If 0, returns
            immediately with any records that are available now. Must not be negative.</dd>
<dt><span class="strong">Returns:</span></dt><dd>map of topic to records since the last fetch for the subscribed list of topics and partitions</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/InvalidOffsetException.html" title="class in org.apache.kafka.clients.consumer">InvalidOffsetException</a></code> - if the offset for a partition or set of
             partitions is undefined or out of range and no offset reset policy has been configured</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors">WakeupException</a></code> - if <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> is called before or while this
             function is called</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/AuthorizationException.html" title="class in org.apache.kafka.common.errors">AuthorizationException</a></code> - if caller does Read access to any of the subscribed
             topics or to the configured groupId</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/KafkaException.html" title="class in org.apache.kafka.common">KafkaException</a></code> - for any other unrecoverable errors (e.g. invalid groupId or
             session timeout, errors deserializing key/value pairs, or any new error cases in future versions)</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(long)</code></a></dd></dl>
</li>
</ul>
<a name="commitSync()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitSync</h4>
<pre>public&nbsp;void&nbsp;commitSync()</pre>
<div class="block">Commit offsets returned on the last <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll()</code></a> for all the subscribed list of topics and partitions.
 <p>
 This commits offsets only to Kafka. The offsets committed using this API will be used on the first fetch after
 every rebalance and also on startup. As such, if you need to store offsets in anything other than Kafka, this API
 should not be used.
 <p>
 This is a synchronous commits and will block until either the commit succeeds or an unrecoverable error is
 encountered (in which case it is thrown to the caller).</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#commitSync()">commitSync</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/CommitFailedException.html" title="class in org.apache.kafka.clients.consumer">CommitFailedException</a></code> - if the commit failed and cannot be retried.
             This can only occur if you are using automatic group management with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List)"><code>subscribe(List)</code></a>,
             or if there is an active group with the same groupId which is using group management.</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors">WakeupException</a></code> - if <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> is called before or while this
             function is called</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/AuthorizationException.html" title="class in org.apache.kafka.common.errors">AuthorizationException</a></code> - if not authorized to the topic or to the
             configured groupId</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/KafkaException.html" title="class in org.apache.kafka.common">KafkaException</a></code> - for any other unrecoverable errors (e.g. if offset metadata
             is too large or if the committed offset is invalid).</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync()"><code>commitSync()</code></a></dd></dl>
</li>
</ul>
<a name="commitSync(java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitSync</h4>
<pre>public&nbsp;void&nbsp;commitSync(java.util.Map&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>,<a href="../../../../../org/apache/kafka/clients/consumer/OffsetAndMetadata.html" title="class in org.apache.kafka.clients.consumer">OffsetAndMetadata</a>&gt;&nbsp;offsets)</pre>
<div class="block">Commit the specified offsets for the specified list of topics and partitions.
 <p>
 This commits offsets to Kafka. The offsets committed using this API will be used on the first fetch after every
 rebalance and also on startup. As such, if you need to store offsets in anything other than Kafka, this API
 should not be used. The committed offset should be the next message your application will consume,
 i.e. lastProcessedMessageOffset + 1.
 <p>
 This is a synchronous commits and will block until either the commit succeeds or an unrecoverable error is
 encountered (in which case it is thrown to the caller).</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#commitSync(java.util.Map)">commitSync</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>offsets</code> - A map of offsets by partition with associated metadata</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/CommitFailedException.html" title="class in org.apache.kafka.clients.consumer">CommitFailedException</a></code> - if the commit failed and cannot be retried.
             This can only occur if you are using automatic group management with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe(java.util.List)"><code>subscribe(List)</code></a>,
             or if there is an active group with the same groupId which is using group management.</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors">WakeupException</a></code> - if <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> is called before or while this
             function is called</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/AuthorizationException.html" title="class in org.apache.kafka.common.errors">AuthorizationException</a></code> - if not authorized to the topic or to the
             configured groupId</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/KafkaException.html" title="class in org.apache.kafka.common">KafkaException</a></code> - for any other unrecoverable errors (e.g. if offset metadata
             is too large or if the committed offset is invalid).</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync(java.util.Map)"><code>commitSync(Map)</code></a></dd></dl>
</li>
</ul>
<a name="commitAsync()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitAsync</h4>
<pre>public&nbsp;void&nbsp;commitAsync()</pre>
<div class="block">Commit offsets returned on the last <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll()</code></a> for all the subscribed list of topics and partition.
 Same as <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync(org.apache.kafka.clients.consumer.OffsetCommitCallback)"><code>commitAsync(null)</code></a></div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#commitAsync()">commitAsync</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync()"><code>commitAsync()</code></a></dd></dl>
</li>
</ul>
<a name="commitAsync(org.apache.kafka.clients.consumer.OffsetCommitCallback)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitAsync</h4>
<pre>public&nbsp;void&nbsp;commitAsync(<a href="../../../../../org/apache/kafka/clients/consumer/OffsetCommitCallback.html" title="interface in org.apache.kafka.clients.consumer">OffsetCommitCallback</a>&nbsp;callback)</pre>
<div class="block">Commit offsets returned on the last <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll()</code></a> for the subscribed list of topics and partitions.
 <p>
 This commits offsets only to Kafka. The offsets committed using this API will be used on the first fetch after
 every rebalance and also on startup. As such, if you need to store offsets in anything other than Kafka, this API
 should not be used.
 <p>
 This is an asynchronous call and will not block. Any errors encountered are either passed to the callback
 (if provided) or discarded.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#commitAsync(org.apache.kafka.clients.consumer.OffsetCommitCallback)">commitAsync</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>callback</code> - Callback to invoke when the commit completes</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync(org.apache.kafka.clients.consumer.OffsetCommitCallback)"><code>commitAsync(OffsetCommitCallback)</code></a></dd></dl>
</li>
</ul>
<a name="commitAsync(java.util.Map, org.apache.kafka.clients.consumer.OffsetCommitCallback)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitAsync</h4>
<pre>public&nbsp;void&nbsp;commitAsync(java.util.Map&lt;<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>,<a href="../../../../../org/apache/kafka/clients/consumer/OffsetAndMetadata.html" title="class in org.apache.kafka.clients.consumer">OffsetAndMetadata</a>&gt;&nbsp;offsets,
               <a href="../../../../../org/apache/kafka/clients/consumer/OffsetCommitCallback.html" title="interface in org.apache.kafka.clients.consumer">OffsetCommitCallback</a>&nbsp;callback)</pre>
<div class="block">Commit the specified offsets for the specified list of topics and partitions to Kafka.
 <p>
 This commits offsets to Kafka. The offsets committed using this API will be used on the first fetch after every
 rebalance and also on startup. As such, if you need to store offsets in anything other than Kafka, this API
 should not be used. The committed offset should be the next message your application will consume,
 i.e. lastProcessedMessageOffset + 1.
 <p>
 This is an asynchronous call and will not block. Any errors encountered are either passed to the callback
 (if provided) or discarded.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#commitAsync(java.util.Map,%20org.apache.kafka.clients.consumer.OffsetCommitCallback)">commitAsync</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>offsets</code> - A map of offsets by partition with associate metadata. This map will be copied internally, so it
                is safe to mutate the map after returning.</dd><dd><code>callback</code> - Callback to invoke when the commit completes</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#commitAsync(java.util.Map,%20org.apache.kafka.clients.consumer.OffsetCommitCallback)"><code>commitAsync(Map, OffsetCommitCallback)</code></a></dd></dl>
</li>
</ul>
<a name="seek(org.apache.kafka.common.TopicPartition, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>seek</h4>
<pre>public&nbsp;void&nbsp;seek(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&nbsp;partition,
        long&nbsp;offset)</pre>
<div class="block">Overrides the fetch offsets that the consumer will use on the next <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(timeout)</code></a>. If this API
 is invoked for the same partition more than once, the latest offset will be used on the next poll(). Note that
 you may lose data if this API is arbitrarily used in the middle of consumption, to reset the fetch offsets</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#seek(org.apache.kafka.common.TopicPartition,%20long)">seek</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seek(org.apache.kafka.common.TopicPartition,%20long)"><code>seek(TopicPartition, long)</code></a></dd></dl>
</li>
</ul>
<a name="seekToBeginning(org.apache.kafka.common.TopicPartition...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>seekToBeginning</h4>
<pre>public&nbsp;void&nbsp;seekToBeginning(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</pre>
<div class="block">Seek to the first offset for each of the given partitions. This function evaluates lazily, seeking to the
 final offset in all partitions only when <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(long)</code></a> or <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#position(org.apache.kafka.common.TopicPartition)"><code>position(TopicPartition)</code></a> are called.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#seekToBeginning(org.apache.kafka.common.TopicPartition...)">seekToBeginning</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seekToBeginning(org.apache.kafka.common.TopicPartition...)"><code>seekToBeginning(TopicPartition...)</code></a></dd></dl>
</li>
</ul>
<a name="seekToEnd(org.apache.kafka.common.TopicPartition...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>seekToEnd</h4>
<pre>public&nbsp;void&nbsp;seekToEnd(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</pre>
<div class="block">Seek to the last offset for each of the given partitions. This function evaluates lazily, seeking to the
 final offset in all partitions only when <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(long)</code></a> or <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#position(org.apache.kafka.common.TopicPartition)"><code>position(TopicPartition)</code></a> are called.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#seekToEnd(org.apache.kafka.common.TopicPartition...)">seekToEnd</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#seekToEnd(org.apache.kafka.common.TopicPartition...)"><code>seekToEnd(TopicPartition...)</code></a></dd></dl>
</li>
</ul>
<a name="position(org.apache.kafka.common.TopicPartition)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>position</h4>
<pre>public&nbsp;long&nbsp;position(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&nbsp;partition)</pre>
<div class="block">Get the offset of the <i>next record</i> that will be fetched (if a record with that offset exists).</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#position(org.apache.kafka.common.TopicPartition)">position</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>partition</code> - The partition to get the position for</dd>
<dt><span class="strong">Returns:</span></dt><dd>The offset</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/InvalidOffsetException.html" title="class in org.apache.kafka.clients.consumer">InvalidOffsetException</a></code> - if no offset is currently defined for
             the partition</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors">WakeupException</a></code> - if <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> is called before or while this
             function is called</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/AuthorizationException.html" title="class in org.apache.kafka.common.errors">AuthorizationException</a></code> - if not authorized to the topic or to the
             configured groupId</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/KafkaException.html" title="class in org.apache.kafka.common">KafkaException</a></code> - for any other unrecoverable errors</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#position(org.apache.kafka.common.TopicPartition)"><code>position(TopicPartition)</code></a></dd></dl>
</li>
</ul>
<a name="committed(org.apache.kafka.common.TopicPartition)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>committed</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/kafka/clients/consumer/OffsetAndMetadata.html" title="class in org.apache.kafka.clients.consumer">OffsetAndMetadata</a>&nbsp;committed(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>&nbsp;partition)</pre>
<div class="block">Get the last committed offset for the given partition (whether the commit happened by this process or
 another). This offset will be used as the position for the consumer in the event of a failure.
 <p>
 This call may block to do a remote call if the partition in question isn't assigned to this consumer or if the
 consumer hasn't yet initialized its cache of committed offsets.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#committed(org.apache.kafka.common.TopicPartition)">committed</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>partition</code> - The partition to check</dd>
<dt><span class="strong">Returns:</span></dt><dd>The last committed offset and metadata or null if there was no prior commit</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors">WakeupException</a></code> - if <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> is called before or while this
             function is called</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/AuthorizationException.html" title="class in org.apache.kafka.common.errors">AuthorizationException</a></code> - if not authorized to the topic or to the
             configured groupId</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/KafkaException.html" title="class in org.apache.kafka.common">KafkaException</a></code> - for any other unrecoverable errors</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#committed(org.apache.kafka.common.TopicPartition)"><code>committed(TopicPartition)</code></a></dd></dl>
</li>
</ul>
<a name="metrics()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>metrics</h4>
<pre>public&nbsp;java.util.Map&lt;<a href="../../../../../org/apache/kafka/common/MetricName.html" title="class in org.apache.kafka.common">MetricName</a>,? extends <a href="../../../../../org/apache/kafka/common/Metric.html" title="interface in org.apache.kafka.common">Metric</a>&gt;&nbsp;metrics()</pre>
<div class="block">Get the metrics kept by the consumer</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#metrics()">metrics</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#metrics()"><code>metrics()</code></a></dd></dl>
</li>
</ul>
<a name="partitionsFor(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionsFor</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../../org/apache/kafka/common/PartitionInfo.html" title="class in org.apache.kafka.common">PartitionInfo</a>&gt;&nbsp;partitionsFor(java.lang.String&nbsp;topic)</pre>
<div class="block">Get metadata about the partitions for a given topic. This method will issue a remote call to the server if it
 does not already have any metadata about the given topic.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#partitionsFor(java.lang.String)">partitionsFor</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>topic</code> - The topic to get partition metadata for</dd>
<dt><span class="strong">Returns:</span></dt><dd>The list of partitions</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors">WakeupException</a></code> - if <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> is called before or while this
             function is called</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/AuthorizationException.html" title="class in org.apache.kafka.common.errors">AuthorizationException</a></code> - if not authorized to the specified topic</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/TimeoutException.html" title="class in org.apache.kafka.common.errors">TimeoutException</a></code> - if the topic metadata could not be fetched before
             expiration of the configured request timeout</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/KafkaException.html" title="class in org.apache.kafka.common">KafkaException</a></code> - for any other unrecoverable errors</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#partitionsFor(java.lang.String)"><code>partitionsFor(String)</code></a></dd></dl>
</li>
</ul>
<a name="listTopics()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listTopics</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,java.util.List&lt;<a href="../../../../../org/apache/kafka/common/PartitionInfo.html" title="class in org.apache.kafka.common">PartitionInfo</a>&gt;&gt;&nbsp;listTopics()</pre>
<div class="block">Get metadata about partitions for all topics that the user is authorized to view. This method will issue a
 remote call to the server.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#listTopics()">listTopics</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Returns:</span></dt><dd>The map of topics and its partitions</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors">WakeupException</a></code> - if <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> is called before or while this
             function is called</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/errors/TimeoutException.html" title="class in org.apache.kafka.common.errors">TimeoutException</a></code> - if the topic metadata could not be fetched before
             expiration of the configured request timeout</dd>
<dd><code><a href="../../../../../org/apache/kafka/common/KafkaException.html" title="class in org.apache.kafka.common">KafkaException</a></code> - for any other unrecoverable errors</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#listTopics()"><code>listTopics()</code></a></dd></dl>
</li>
</ul>
<a name="pause(org.apache.kafka.common.TopicPartition...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pause</h4>
<pre>public&nbsp;void&nbsp;pause(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</pre>
<div class="block">Suspend fetching from the requested partitions. Future calls to <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(long)</code></a> will not return
 any records from these partitions until they have been resumed using <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#resume(org.apache.kafka.common.TopicPartition...)"><code>resume(TopicPartition...)</code></a>.
 Note that this method does not affect partition subscription. In particular, it does not cause a group
 rebalance when automatic assignment is used.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#pause(org.apache.kafka.common.TopicPartition...)">pause</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>partitions</code> - The partitions which should be paused</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#pause(org.apache.kafka.common.TopicPartition...)"><code>pause(TopicPartition...)</code></a></dd></dl>
</li>
</ul>
<a name="resume(org.apache.kafka.common.TopicPartition...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resume</h4>
<pre>public&nbsp;void&nbsp;resume(<a href="../../../../../org/apache/kafka/common/TopicPartition.html" title="class in org.apache.kafka.common">TopicPartition</a>...&nbsp;partitions)</pre>
<div class="block">Resume specified partitions which have been paused with <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#pause(org.apache.kafka.common.TopicPartition...)"><code>pause(TopicPartition...)</code></a>. New calls to
 <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#poll(long)"><code>poll(long)</code></a> will return records from these partitions if there are any to be fetched.
 If the partitions were not previously paused, this method is a no-op.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#resume(org.apache.kafka.common.TopicPartition...)">resume</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>partitions</code> - The partitions which should be resumed</dd><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#resume(org.apache.kafka.common.TopicPartition...)"><code>resume(TopicPartition...)</code></a></dd></dl>
</li>
</ul>
<a name="close()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>close</h4>
<pre>public&nbsp;void&nbsp;close()</pre>
<div class="block">Close the consumer, waiting indefinitely for any needed cleanup. If auto-commit is enabled, this
 will commit the current offsets. Note that <a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a> cannot be use to interrupt close.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>close</code>&nbsp;in interface&nbsp;<code>java.io.Closeable</code></dd>
<dt><strong>Specified by:</strong></dt>
<dd><code>close</code>&nbsp;in interface&nbsp;<code>java.lang.AutoCloseable</code></dd>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#close()">close</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#close()"><code>close()</code></a></dd></dl>
</li>
</ul>
<a name="wakeup()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>wakeup</h4>
<pre>public&nbsp;void&nbsp;wakeup()</pre>
<div class="block">Wakeup the consumer. This method is thread-safe and is useful in particular to abort a long poll.
 The thread which is blocking in an operation will throw <a href="../../../../../org/apache/kafka/common/errors/WakeupException.html" title="class in org.apache.kafka.common.errors"><code>WakeupException</code></a>.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html#wakeup()">wakeup</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/apache/kafka/clients/consumer/Consumer.html" title="interface in org.apache.kafka.clients.consumer">Consumer</a>&lt;<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">K</a>,<a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html" title="type parameter in KafkaConsumer">V</a>&gt;</code></dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup()"><code>wakeup()</code></a></dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/kafka/clients/consumer/InvalidOffsetException.html" title="class in org.apache.kafka.clients.consumer"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/kafka/clients/consumer/MockConsumer.html" title="class in org.apache.kafka.clients.consumer"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html" target="_top">Frames</a></li>
<li><a href="KafkaConsumer.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
